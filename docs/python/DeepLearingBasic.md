# ğŸ›£[Deep Learning]Stanford CS224n:Natural Language Processing  
---
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

!!! info "æƒ³è¯´çš„è¯ğŸ‡"
    <font size = 3.5>
    åˆæ¬¡æ¥è§¦æ·±åº¦å­¦ä¹ æ˜¯åœ¨å¤§ä¸€å¯’å‡å‡†å¤‡æ‰“æ•°æ¨¡æ¯”èµ›çš„æ—¶å€™,æ–­æ–­ç»­ç»­ä¹Ÿå°±å­¦äº†ä¸€å°æ®µæ—¶é—´,å…ˆå°è¯•äº†ææ²çš„[Dive into deep learing](https://zh-v2.d2l.ai)åé¢åœ¨ç¡®å®šæœ¬ç§‘ç§‘ç ”æ–¹å‘åå†³å®šçœ‹cs224nå’ŒHugging faceçš„[NLPcourse](https://huggingface.co/learn/nlp-course/chapter1/1)æŒæ¡ä¸€äº›åŸºç¡€çš„å†…å®¹,å› æ­¤ä¸“é—¨å†™ä¸‹æ¥ç”¨ä½œå¤ä¹ (å¤§ä½¬è½»å–·ğŸ˜¥)
    
    ğŸ”è¯¾ç¨‹ç½‘ç«™ï¼šhttp://web.stanford.edu/class/cs224n/index.html
    
    ğŸ‘€ä¸€äº›èµ„æº: 
    https://www.bilibili.com/video/BV1jt421L7ui/(Bç«™åŒè¯­ç²¾ç¿»)
    https://www.showmeai.tech/tutorials/36?articleId=231(è¯¾ä»¶ç¿»è¯‘+çŸ¥è¯†æ¢³ç†)

    </font>

## ğŸ¥—Lecture 1 
---
<font size = 4>

!!! note "Representing words as discrete symbols - ont-hot vectors"
    <font size = 4>
    The tradional NLP use <B>one-hot vectors</B> to represent words as discrete symbol,

    ```python
    import pandas 
    from sklearn.preprocessing import OneHotEncoder
    
    words = ['apple', 'banana', 'orange']
    df = pd.DataFrame(words, columns = ['word'])
    one_hot_encoded = pd.get_dummies(df['word'])
    
    encoder = OneHotEncoder()
    one_hot_encoded = encoder.fit_transform(df[['word']])
    ``` 
    </font>
</font>