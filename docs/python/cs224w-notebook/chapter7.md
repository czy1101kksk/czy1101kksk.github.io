# ğŸ›£[Deep Learning]Stanford CS224w:Machine Learning with Graphs
---
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

!!! info "æƒ³è¯´çš„è¯ğŸ‡"
    <font size = 3.5>
    
    ğŸ”è¯¾ç¨‹ç½‘ç«™ï¼šhttp://web.stanford.edu/class/cs224w/
    
    ğŸ‘€ä¸€äº›èµ„æº: 
    Bç«™ç²¾è®²ï¼šhttps://www.bilibili.com/video/BV1pR4y1S7GA/?spm_id_from=333.337.search-card.all.click&vd_source=280e4970f2995a05fdeab972a42bfdd0
    
    https://github.com/TommyZihao/zihao_course/tree/main/CS224W
    
    Slides: http://web.stanford.edu/class/cs224w/slides
    
    </font>

<B>Heterogeneous Message</B>
---

Message functionï¼š $\mathbf{m}_u^{(l)} = MSG_r^{(l)} (\mathbf{h}_u^{(l-1)}), \ r=(u,e,v)$

Observation: A node could receive multiple types of messages. <B>Num of message type = Num of relation type. </B>

$r=(u,e,v)$ is the  relation type between node $u$ that sends the message, edge type $e$ , and node $v$ that receive the message.

<B>Heterogeneous Aggregation</B>
---

Observation: Each node could receive multiple types of messages from its neighbors, and multiple neighbors may belong to each message type.

$$
h_v^{(l)} = AGG^{(l)}_{all} \Big( AGG^{(l)}_r (\{ \mathbf{m}^{(l)}_u, u \in N_r(v)\}) \Big)
$$

- $AGG^{(l)}_r$ï¼šaggregate the messages that belongs to the relation type

- $AGG^{(l)}_{all}$ï¼šaggregate across the edge types

![](./img2/recap.png)



## Heterogeneous Graphs Transformer(HGT)

![](./img2/5.png)

![](./img2/6.png)

Innovation: Decompose heterogeneous graph to <B>Node-type and edge-type dependent attention mechanism</B>

![](./img2/7.png)

$$
\begin{aligned}
AttenHead^i (s,e,t) =& (K^i(s) W^{Att}_{\phi(e)} Q^i(t)^T) \\
K^i(s) = KLinear^i_{\tau(s)} &(H^{(l-1)[s]}) \\
Q^i(t) = QLinear^i_{\tau(t)} &(H^{(l-1)[t]}) \\
\end{aligned}
$$

Each relation $(Type(s), Relation(e), Type(t))$ has a distinct set of projection weights

![](./img2/8.png)

![](./img2/9.png)

![](img2/12.png)

### Understanding Heterogeneous Graph Transformer

é˜…è¯»åœ°å€ï¼š[Heterogeneous Graph Transformer](https://arxiv.org/abs/2003.01332)

![](./img2/hgt.png)

å›é¡¾GATï¼Œå…¶å‡è®¾æ‰€æœ‰çš„èŠ‚ç‚¹æ‹¥æœ‰ç›¸åŒçš„ç‰¹å¾åˆ†å¸ƒï¼ˆä½¿ç”¨äº†åŒä¸€ä¸ªæƒé‡çŸ©é˜µ$W$ï¼‰ï¼Œä½†å¯¹äºå¼‚è´¨å›¾æ¥è¯´ï¼Œä¸åŒç±»å‹çš„èŠ‚ç‚¹æ‹¥æœ‰ä¸åŒçš„ç‰¹å¾åˆ†å¸ƒï¼Œå› æ­¤éœ€è¦ä¸ºä¸åŒç±»å‹çš„èŠ‚ç‚¹ä½¿ç”¨ä¸åŒçš„æƒé‡çŸ©é˜µ$W$ã€‚

å› æ­¤ï¼Œè¯¥è®ºæ–‡è®¾è®¡äº†```Heterogeneous Mutual Attention```æœºåˆ¶ã€‚è®¾å®šä¸€ä¸ªç›®æ ‡èŠ‚ç‚¹$t$ï¼Œä»¥åŠå…¶å±äºä¸åŒåˆ†å¸ƒçš„æ‰€æœ‰é‚»å±…$s \in N(t)$ï¼Œæˆ‘ä»¬å¸Œæœ›æ ¹æ®èŠ‚ç‚¹ä¹‹é—´çš„å…ƒå…³ç³»æ¥è®¡ç®—ç›¸äº’æ³¨æ„åŠ›$(\tau(s), \phi(e), \tau(t))$ä¸‰å…ƒç»„ã€‚

$$
\begin{aligned}
\text{Attention}_{HGT} (s,e,t)&= Softmax_{\forall s \in N(t)} \Big( ||_{i\in [1,h]} \text{Att-head}^i (s,e,t) \Big) \\
\text{Att-head}^i (s,e,t) &= (K^i(s) W^{Att}_{\phi(e)} Q^i(t)^T) \cdot \frac{\mu_{<\tau(s), \phi(e), \tau(t)>}}{\sqrt{d}} \\
K^i(s) &= \text{K-Linear}^i_{\tau(s)} &(H^{(l-1)[s]}) \\
Q^i(t) &= \text{Q-Linear}^i_{\tau(t)} &(H^{(l-1)[t]}) \\
\end{aligned}
$$

å¯¹äºç¬¬iä¸ªæ³¨æ„åŠ›å¤´$\text{Att-head}^i (s,e,t)$ï¼Œæˆ‘ä»¬ä½¿ç”¨çº¿æ€§æŠ•å½±$\text{K-Linear}_{\tau(s)}^i$å°†$\tau(s)$ç±»å‹çš„æºèŠ‚ç‚¹$s$æŠ•å½±åˆ°$i$-th $Key$å‘é‡$K^i(s)$ï¼š$\mathbb{R}^d \rightarrow \mathbb{R}^{\frac{d}{h}}$ï¼Œå…¶ä¸­$h$æ˜¯æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼Œ$\frac{d}{h}$æ˜¯æ¯ä¸ªå¤´çš„å‘é‡è¡¨ç¤ºã€‚

> æ¯ç§ç±»å‹$\tau(s)$çš„èŠ‚ç‚¹éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„çº¿æ€§æŠ•å½±$\text{Linear}_{\tau(s)}^i$æ¥æœ€å¤§é™åº¦åœ°å»ºæ¨¡åˆ†å¸ƒå·®å¼‚ã€‚

å¼‚æ„å›¾çš„ä¸€ä¸ªç‹¬ç‰¹ç‰¹å¾æ˜¯èŠ‚ç‚¹ç±»å‹å¯¹ä¹‹é—´å¯èƒ½å­˜åœ¨ä¸åŒçš„è¾¹å…³ç³»ï¼Œå› æ­¤æˆ‘ä»¬ä¸ºæ¯ä¸ªè¾¹ç±»å‹$\phi(e)$å®šä¹‰ä¸€ä¸ªæŠ•å½±çŸ©é˜µ$W^{Att}_{\phi(e)} \in \mathbb{R}^{\frac{d}{h} \times \frac{d}{h}}$ï¼Œ

å¹¶ä¸”ï¼Œç”±äºå¹¶éæ‰€æœ‰çš„å…³ç³»è¿æ¥å¯¹ç›®æ ‡èŠ‚ç‚¹çš„è´¡çŒ®ç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªå…ˆéªŒå¼ é‡ï¼ˆprior tensorï¼‰$\mu \in \mathbb{R}^{|\mathcal{A}| \times |\mathcal{R}| \times |\mathcal{A}|}$ï¼Œæ¥è¡¨ç¤ºæ¯ä¸ªå…ƒå…³ç³»ä¸‰å…ƒç»„çš„ä¸€èˆ¬æ„ä¹‰ï¼Œä½œä¸ºå¯¹æ³¨æ„åŠ›çš„è‡ªé€‚åº”ç¼©æ”¾ã€‚

æœ€åï¼Œæˆ‘ä»¬å°†$h$ä¸ªæ³¨æ„åŠ›å¤´è¿æ¥åœ¨ä¸€èµ·ä»¥è·å¾—æ¯ä¸ªèŠ‚ç‚¹å¯¹çš„æ³¨æ„åŠ›å‘é‡ã€‚å¯¹äºæ¯ä¸ªç›®æ ‡èŠ‚ç‚¹$t$ï¼Œæˆ‘ä»¬ä»å…¶é‚»å±…$N (t)$ä¸­æ”¶é›†æ‰€æœ‰æ³¨æ„åŠ›å‘é‡å¹¶è¿›è¡Œsoftmaxï¼Œæœ‰$\sum_{\forall s \in N(t)} \text{Attention}_{HGT} (s,e,t) = \mathbf{1}_{h \times 1}$

$$
\text{Message}_{HGT} (s,e,t) = ||_{i\in [1,h]} \text{MSG-head}^i (s,e,t) \\ \text{MSG-head}^i (s,e,t) = \text{M-Linear}^i_{\tau(t)} (H^{(l-1)}[s]) W^{MSG}_{\phi(e)}
$$

å…¶ä¸­$\text{M-Linear}^i_{\tau(t)}: \ \mathbb{R}^d \rightarrow \mathbb{R}^{\frac{d}{h}}$æ˜¯ç›®æ ‡èŠ‚ç‚¹$t$çš„çº¿æ€§æŠ•å½±ï¼Œ$W^{MSG}_{\phi(e)} \in \mathbb{R}^{\frac{d}{h} \times \frac{d}{h}}$æ˜¯è¾¹ç±»å‹$\phi(e)$çš„æŠ•å½±çŸ©é˜µã€‚æœ€åè¿æ¥æ‰€æœ‰$h$ä¸ªæ¶ˆæ¯å¤´ä»¥è·å¾—æ¯ä¸ªèŠ‚ç‚¹å¯¹çš„æ¶ˆæ¯$\text{Message}_{HGT}(s, e, t)$ã€‚

$$
\tilde{H}^{(l)}[t] = \mathop{\oplus}\limits_{\forall s \in N(t)} (\text{Attention}_{HGT} (s,e,t) \cdot \text{Message}_{HGT} (s,e,t))
$$

è¿™å°†ä¿¡æ¯èšåˆåˆ°æ¥è‡ªä¸åŒç‰¹å¾åˆ†å¸ƒçš„æ‰€æœ‰é‚»å±…ï¼ˆæºèŠ‚ç‚¹ï¼‰çš„ç›®æ ‡èŠ‚ç‚¹$t$ã€‚

$$
H^{(l)}[t] = \text{A-Linear}_{\tau(t)} (\sigma(\tilde{H}^{(l)}[t])) + H^{(l-1)}[t]
$$

<B>Relative Temporal Encoding</B>

![](./img2/hgt2.png)

æœ¬æ–‡æå‡ºäº†ç›¸å¯¹æ—¶é—´ç¼–ç  (RTE) æœºåˆ¶æ¥æ¨¡æ‹Ÿå¼‚æ„å›¾ä¸­çš„åŠ¨æ€ä¾èµ–å…³ç³»ã€‚RTEå—åˆ° Transformerçš„ä½ç½®ç¼–ç æ–¹æ³•çš„å¯å‘ã€‚ç»™å®šä¸€ä¸ªæºèŠ‚ç‚¹$s$å’Œä¸€ä¸ªç›®æ ‡èŠ‚ç‚¹$t$ï¼Œä»¥åŠå“åº”çš„æ—¶é—´æˆ³$T(s)$å’Œ$T(t)$ï¼Œæˆ‘ä»¬å°†ç›¸å¯¹æ—¶é—´é—´éš”$\Delta T(t,s) = T(t) - T(s)$è¡¨ç¤ºä¸ºè·å¾—ç›¸å¯¹æ—¶é—´ç¼–ç $\text{RTE}(\Delta T(t,s))$çš„ç´¢å¼•ã€‚

$$
\begin{aligned}
Base (\Delta T(t,s), 2i) &= \sin{(\Delta T(t,s) / 10000^{2i/d})} \\
Base (\Delta T(t,s), 2i+1) &= \cos{(\Delta T(t,s) / 1 0000^{(2i+1)/d})} \\
RTE(\Delta T(t,s)) &= \text{T-Linear} (Base(\Delta T_{t,s})) \\
\end{aligned}
$$

æœ€åï¼Œå°†ç›¸å¯¹äºç›®æ ‡èŠ‚ç‚¹ t çš„æ—¶é—´ç¼–ç æ·»åŠ åˆ°æºèŠ‚ç‚¹ s çš„è¡¨ç¤ºä¸­:

$$
\tilde{H}^{(l-1)}[t] = H^{(l-1)}[t] + RTE(\Delta T(t,s))
$$

