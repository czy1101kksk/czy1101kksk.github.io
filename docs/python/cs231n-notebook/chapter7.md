# ğŸ›£Stanford CS231n:Deep Learning for Computer Vision  
---

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

!!! info "æƒ³è¯´çš„è¯ğŸ‡"
    
    <font size = 3.5>
    
    ğŸ”è¯¾ç¨‹ç½‘ç«™ï¼š[https://cs231n.stanford.edu/](https://cs231n.stanford.edu/)
    
    2024ç‰ˆPPT: [https://cs231n.stanford.edu/slides/2024/](https://cs231n.stanford.edu/slides/2024/)
    
    </font>

###  Sequence to Sequence with RNNs 
---

![](./cs231-img/seq2seq.png)

å·¦ä¾§çš„RNNï¼ˆEncoderï¼š$h_t=f_w(x_t,h_{t-1})$ï¼‰å°†è¾“å…¥åºåˆ—ç¼–ç æ€»ç»“æˆ2ä¸ªå‘é‡ï¼ˆ$s_0$ï¼Œ$c$ï¼‰ï¼Œ$s_0$ä½œä¸ºè§£ç å™¨çš„åˆå§‹çŠ¶æ€(initial decoder state,æˆ–è€…è®¾ç½®ä¸º0)ï¼Œ$c$ä½œä¸ºè§£ç å™¨çš„ä¸Šä¸‹æ–‡å‘é‡ï¼ˆContext vectorï¼Œtansfer encoded sequence information to the decoderï¼‰ã€‚

å³ä¾§çš„RNN(decoder)å°†è¿™ä¸ªå‘é‡è§£ç æˆè¾“å‡ºåºåˆ—ã€‚

- During Training:
    åœ¨è®­ç»ƒç½‘ç»œè¿‡ç¨‹ä¸­ï¼Œæ¯æ¬¡ä¸ä½¿ç”¨ä¸Šä¸€ä¸ªstateçš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªstateçš„è¾“å…¥ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨è®­ç»ƒæ•°æ®çš„æ ‡å‡†ç­”æ¡ˆ(ground truth)çš„å¯¹åº”ä¸Šä¸€é¡¹ä½œä¸ºä¸‹ä¸€ä¸ªstateçš„è¾“å…¥,ä¸ç®¡è¾“å‡ºæ˜¯å¦æ­£ç¡®ï¼ˆteacher-forcingï¼‰

    ![](./cs231-img/tea.png)

- During Test-time:

    æˆ‘ä»¬ä»è¾“å‡ºä¸­è¿›è¡ŒæŠ½æ ·ï¼Œç›´åˆ°æŠ½ä¸­```[STOP]```

æ˜¾ç„¶ï¼Œè¿™ä¸ªSeq2seqæ¨¡å‹å¹¶ä¸é€‚ç”¨äºé•¿æ–‡æœ¬ä»»åŠ¡
ï¼Œå› ä¸ºå¦‚æœè¾“å…¥åºåˆ—è¿‡é•¿ï¼ŒåŸºäºRNNçš„ç¼–ç å™¨æ²¡æœ‰èƒ½åŠ›å»æ•æ‰è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œå¯¼è‡´è§£ç å™¨æ— æ³•ç”Ÿæˆå‡†ç¡®çš„è¾“å‡ºã€‚å¹¶ä¸”ï¼Œå¸Œæœ›ç”¨å•ä¸€çš„ä¸Šä¸‹æ–‡å‘é‡$c$å»æ€»ç»“æ•´ä¸ªé•¿åºåˆ—ä¿¡æ¯ï¼Œæ˜¾ç„¶æ˜¯ä¸ç°å®çš„ã€‚

æˆ‘ä»¬å¯ä»¥æƒ³è±¡ä¸€ç§ç®—æ³•ï¼Œä¸æ˜¯ä½¿ç”¨å•ä¸ªçš„ä¸Šä¸‹æ–‡å‘é‡$c$ï¼Œ
è€Œæ˜¯åœ¨decoderçš„æ¯ä¸ªæ—¶é—´æ­¥ä¸­è®¡ç®—ä¸€ä¸ªä¸Šä¸‹æ–‡å‘é‡ï¼Œå³ç»™äºˆdecoderä¸“æ³¨äºè¾“å…¥åºåˆ—çš„ä¸åŒéƒ¨åˆ†ï¼Œé€‰æ‹©æˆ–è€…é‡å»ºä¸€ä¸ªæ–°çš„ä¸Šä¸‹æ–‡å‘é‡çš„èƒ½åŠ›ã€‚

![](./cs231-img/Bahdanau.png)

å¦‚ä¸Šï¼Œæˆ‘ä»¬ç¼–å†™ä¸€ä¸ªå¯¹é½å‡½æ•°$f_{att}$ï¼ˆalignment functionï¼Œé€šå¸¸ä¸ºMLPsï¼‰ï¼Œå°†Encoderçš„éšè—çŠ¶æ€ä¸$s_0$è¾“å…¥å¾—åˆ°alignment scoresï¼ˆhow much should we attend to each hidden state of encoderï¼‰ï¼Œç„¶åä½¿ç”¨softmaxå‡½æ•°å½’ä¸€åŒ–å¾—åˆ°æƒé‡$a_{t,i}$ï¼ˆattention weightsï¼‰ã€‚

å¾—åˆ°æƒé‡åï¼Œæˆ‘ä»¬ä½¿ç”¨åŠ æƒæ±‚å’Œå¾—åˆ°ä¸Šä¸‹æ–‡å‘é‡$c_t$ï¼Œå³ï¼š
$$
c_t=\sum_{i=1}^{T_x}a_{t,i}h_i
$$
> å…¶ä¸­ï¼Œ$a_{t,i}$è¡¨ç¤ºç¬¬$t$ä¸ªdecoderçš„éšè—çŠ¶æ€å¯¹ç¬¬$i$ä¸ªencoderçš„éšè—çŠ¶æ€$h_i$çš„æ³¨æ„åŠ›æƒé‡ã€‚

![](./cs231-img/r.png)

æ¥ä¸‹æ¥é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œå°†ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„çŠ¶æ€$s_1$ä¸Encoderçš„å„ä¸ª$h_t$è¾“å…¥$f_{att}$,å¾—åˆ°$c_2$ï¼Œä»¥æ­¤ç±»æ¨ã€‚

å› æ­¤ï¼š

-  è¾“å…¥åºåˆ—çš„ä¿¡æ¯ä¼ é€’ä¸ä¼šå—å•ä¸€ä¸Šä¸‹æ–‡å‘é‡çš„é˜»ç¢

- Decoderçš„æ¯ä¸ªæ—¶é—´æ­¥éƒ½èƒ½å¤Ÿâ€œæŸ¥çœ‹â€è¾“å…¥åºåˆ—çš„ä¸åŒéƒ¨åˆ†ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡çš„è¾“å‡ºåºåˆ—ã€‚

å¯¹äºè®¡ç®—å¾—åˆ°çš„æ¦‚ç‡åˆ†å¸ƒ$a_{t,i}$è¿›è¡ŒçŸ©é˜µå¯è§†åŒ–ï¼Œå¯ä»¥çœ‹åˆ°decoderè¾“å‡ºçš„æ¯ä¸ªå•è¯å…³æ³¨äº†è¾“å…¥åºåˆ—çš„ä¸åŒéƒ¨åˆ†ï¼š

![](./cs231-img/visu.png)

æˆ‘ä»¬å°†ä¸¤ç§è¯­è¨€çš„å•è¯è¿›è¡Œå¯¹åº”ï¼Œå¯ä»¥å‘ç°attentionæœºåˆ¶å¾ˆå¥½åœ°æ•æ‰åˆ°äº†ä¸¤ç§è¯­è¨€ä¸­åŒä¹‰å•è¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼š

![](./cs231-img/visua1.png)

äº‹å®ä¸Šï¼Œattentionæœºåˆ¶å¹¶ä¸å…³å¿ƒè¾“å…¥æ˜¯å¦æ˜¯ä¸€ä¸ªé¡ºåºåºåˆ—ï¼ˆordered sequence ï¼‰ï¼Œè€Œæ˜¯å¯¹æ•´ä¸ªè¾“å…¥åºåˆ—è¿›è¡Œâ€œæ³¨æ„â€ã€‚

### Image Captioning with RNNs and Attention
---

![](./cs231-img/sps.png)

![](./cs231-img/sssss.png)

![](./cs231-img/s3.png)

![](./cs231-img/seee.png)

### General Attention Layer
---

æˆ‘ä»¬å…ˆå¯¹image captioningä¸­çš„attentionæœºåˆ¶è¿›è¡Œæ€»ç»“ï¼š

<B>Input</B>:

- Features: $\mathbf{z}$ (shapeï¼šH x W x D)

- Queryï¼š$\mathbf{h}$ (shapeï¼šD)

$D$è¡¨ç¤ºç‰¹å¾å›¾æ•°

<B>Operations</B>:

- Alignment func: $e_{i,j} = f_{att}(\mathbf{z}_{i,j}, \mathbf{h})$ (shape: H x W)

- Attention weights: $\mathbf{a} = softmax(\mathbf{e})$ (shape: H x W)

<B>Outputs:</B>

- Context vector: $c = \sum_{i=1}^{H}\sum_{j=1}^{W}a_{i,j}\mathbf{z}_{i,j}$ (shape: D)

![](./cs231-img/imi.png)

å‰é¢æˆ‘ä»¬æåŠåˆ°ï¼Œattentionæœºåˆ¶ä¸å…³æ³¨è¾“å…¥æ•°æ®çš„é¡ºåºï¼Œå› æ­¤æˆ‘ä»¬å°†input vectorsæ‹‰ä¼¸æˆ$\mathbf{x}$ï¼ˆshape: N x Dï¼‰ï¼Œå…¶ä¸­$N = H \times W$ã€‚

> ç†è§£ï¼šå°†$H \times W$å±•å¼€æˆ$N$ï¼Œå³è¾“å…¥çš„ä¿¡æ¯å…±æœ‰$N$ä¸ªå‘é‡ï¼Œæ¯ä¸ªå‘é‡çš„ç»´åº¦ä¸º$D$ã€‚å¦‚æœæ˜¯å›¾åƒçš„è¯ï¼Œ$N$ä¸ªå‘é‡çš„å…¶ä¸­ä¸€ä¸ªå¯¹åº”åŸå›¾ç‰‡çš„æŸä¸€å—ï¼ˆæ„Ÿå—é‡ï¼‰ï¼›å¦‚æœæ˜¯æ–‡æœ¬åºåˆ—çš„è¯ï¼Œ$N$ä¸ªå‘é‡çš„å…¶ä¸­ä¸€ä¸ªå¯¹åº”æ–‡æœ¬åºåˆ—ä¸­çš„æŸä¸ªè¾“å…¥è¯­å¥/å•è¯ã€‚å¦‚ä¸‹å›¾ï¼Œè¾“å…¥çš„æ˜¯200ä¸ªåºåˆ—ï¼Œæ¯ä¸ªåºåˆ—é•¿åº¦ä¸º800![](./cs231-img/xx.png)


å¯¹äº$f_{att}$å‡½æ•°ï¼Œæˆ‘ä»¬å°†å…¶å®šä¹‰ä¸ºç‚¹ç§¯æ“ä½œ(dot product)ï¼Œå³ï¼š
$$
e_i = h \cdot x_i
$$

ä¹Ÿå¯ä»¥ä½¿ç”¨ç¼©æ”¾ç‚¹ç§¯(scaled dot product)ï¼š

$$
e_i = \frac{h \cdot x_i}{\sqrt{D}}
$$

æ”¹ç”¨scaled dot productçš„ç†ç”±ï¼š

> We suspect that for large values of $d_k$, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely samll gradients.

å½“è¾“å…¥ä¿¡æ¯çš„ç»´æ•°$d$å¾ˆå¤§æ—¶ï¼Œç‚¹ç§¯æ‰€å¾—ï¼ˆdot productï¼‰çš„å€¼ç”±å¾ˆå¤šé¡¹ç›¸åŠ è€Œæˆï¼Œé€šå¸¸ä¼šæœ‰æ¯”è¾ƒå¤§çš„æ–¹å·®ã€‚

å‡è®¾ä¸Šè¿°çš„$h$ä¸$x$(ä¸Šæ–‡çš„$x_i$å‘é‡)ç›¸äº’ç‹¬ç«‹ä¸”å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1

$$
\mathbf{E} [h_i] = \mathbf{E} [x_i] = 0 
$$

$$
\mathbf{Var} [h_i] = \mathbf{E} [h_i^2] - (\mathbf{E} (h_i))^2 = \mathbf{E} [h_i^2] = 1\\
$$

$$
\mathbf{Var} [x_i] = \mathbf{E} [x_i^2] - (\mathbf{E} (x_i))^2 = \mathbf{E} [x_i^2] = 1
$$

å› ä¸º$h_i$ä¸$x_i$ç›¸äº’ç‹¬ç«‹ï¼Œæ‰€ä»¥ï¼š

$$
\mathbf{Cov}(h_i,x_i) = \mathbf{E} [ (h_i-\mathbf{E} [h_i]) (x_i-\mathbf{E} [x_i]) ] 
$$

$$
= \mathbf{E}[h_i x_i] - \mathbf{E}[h_i] \mathbf{E}[x_i]= 0
$$

å› æ­¤ï¼š$\mathbf{E}[h_i x_i] = \mathbf{E}[h_i] \mathbf{E}[x_i]= 0$


å¯å¾—ï¼š

$$
\mathbf{Var} (h_i \cdot x_i) = \mathbf{E} [(h_i \cdot x_i)^2] - (\mathbf{E} [h_i \cdot x_i])^2 
$$

$$
= \mathbf{E} [(h_i \cdot x_i)^2] = \mathbf{E} [h_i^2] \mathbf{E} [x_i^2]\\
$$

$$
= \mathbf{Var}(h_i) \mathbf{Var}(x_i) = 1
$$

ç»¼ä¸Šï¼š

$$
\mathbf{Var}(h \cdot x) = \sum_{i=1}^D  \mathbf{Var} (h_i \cdot x_i) = D
$$

å› æ­¤ï¼Œå½“$d$å¾ˆå¤§æ—¶ï¼Œ$h \cdot x$æ–¹å·®çš„å€¼ä¹Ÿä¼šå˜å¤§

è€Œå¯¹äºsoftmaxå‡½æ•°ï¼Œæœ‰ï¼š

$$
Softmax(x_i) = \frac{e^{x_i}}{\sum_{j=1}^N e^{x_j}} \\
$$

$$
\frac{\partial S(x_i)}{\partial x_i} = Softmax(x_i) (1 - Softmax(x_i))
$$

å› æ­¤ï¼Œå½“$d$å¾ˆå¤§æ—¶ï¼Œå¾—åˆ°çš„$x_i$å¯èƒ½å‡ºç°æå¤§/æå°çš„æƒ…å†µï¼Œå¯¼è‡´è®¡ç®—çš„æ¢¯åº¦å€¼ä¼šè¶‹è¿‘äº0ï¼Œå¼•èµ·æ¢¯åº¦æ¶ˆå¤±ã€‚

è‹¥ä½¿ç”¨ç¼©æ”¾ç‚¹ç§¯(scaled dot product)ï¼Œåˆ™å¯ä»¥ä½¿å¾—æ–¹å·®ç¼©å°ä¸º1ï¼š

$$
\mathbf{Var} (\frac{h \cdot x}{\sqrt{D}}) = \frac{1}{D} \mathbf{Var}(h \cdot x) = \frac{1}{D} \times D = 1
$$

è¿™æ—¶ï¼Œsoftmax å‡½æ•°çš„æ¢¯åº¦å°±ä¸å®¹æ˜“è¶‹è¿‘äºé›¶äº†ï¼Œå› æ­¤ä½¿ç”¨ç¼©æ”¾ç‚¹ç§¯(scaled dot product)å¯ä»¥é¿å…æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ã€‚

![](./cs231-img/sb.png)

![](./cs231-img/ul.png)

å®é™…ä¸Šï¼ŒDecoderçš„æ¯ä¸ªæ—¶é—´æ­¥éƒ½å¯¹åº”ä¸€ä¸ªquery vectortï¼ˆæ³¨æ„åŠ›ä¸åŒï¼‰ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å°†æ‹“å±•ä¸º$\mathbf{q}$ï¼ˆshapeï¼šM x Dï¼‰

$\mathbf{e} = \mathbf{q} \mathbf{Z^T}$ï¼ˆshapeï¼šM x Nï¼‰


å¯¹åº”çš„ï¼Œ$\mathbf{a} = Softmax(\mathbf{e},dim=1)$ ï¼ˆshapeï¼šM x Nï¼‰

> shapeï¼šM x Nï¼Œå³ä¸€å…±Mä¸ªquery vectoräº§ç”Ÿçš„æƒé‡å‘é‡$\mathbf{a_j}ï¼Œj=1,2,..,M$ï¼Œæ¯ä¸ªæƒé‡å‘é‡ä¸­æœ‰Nä¸ªæƒé‡ï¼ˆå¯¹è¾“å…¥çš„Nä¸ªä¿¡æ¯çš„ä¸åŒæ³¨æ„åŠ›ï¼‰$a_{i,j}ï¼Œi = 1,2,...,N$

Output context vectors ï¼š$Y = \mathbf{a} \mathbf{X}$ ï¼ˆshapeï¼šM x Dï¼‰ï¼Œ$y_i = \sum_j a_{i,j} x_j$ï¼ˆè¾“å…¥å‘é‡çš„åŠ æƒç»„åˆï¼‰

å›é¡¾ä¸Šè¿°è®¡ç®—è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä½¿ç”¨query vectorä¸input vectorè®¡ç®—æ³¨æ„åŠ›æƒé‡ï¼Œç„¶åä½¿ç”¨æ³¨æ„åŠ›æƒé‡å¯¹input vectorè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°Output context vectorsã€‚è¿™ä¸ªè¿‡ç¨‹ä¸­åœ¨ä¸¤ä¸ªä¸åŒåŠŸèƒ½ä¸Šä½¿ç”¨äº†input vectorã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡æ·»åŠ ä¸åŒçš„FCå±‚æ¥ä»input vectorä¸­å¾—åˆ°key vectorä¸value vectorï¼Œä»è€Œå®ç°æ›´å¤æ‚ï¼ˆadd more expressivityï¼‰çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚

- key vector: $k = xW_k$ï¼Œï¼ˆshape of $W_kï¼šD \times D_k$ï¼‰ï¼ˆshape of $kï¼šN \times D_k$ï¼‰

- value vector: $v = xW_v$ï¼Œï¼ˆshape of $W_vï¼šD \times D_v$ï¼‰ï¼ˆshape of $vï¼šN \times D_v$ï¼‰

ç›¸åº”çš„ï¼Œquery vectorsï¼š$\mathbf{q}$çš„shapeä¸ºï¼š$M \times D_k$


$\mathbf{e} = \mathbf{q} k^T$ï¼Œï¼ˆshape of $eï¼šM \times N$ï¼‰, 

$e_{i,j} = \mathbf{q_i} k_j^T / \sqrt{D_k}$ (kçš„ç‰¹å¾æ•°ä¸º$D_k$)

$Y = \mathbf{a} v$ï¼Œï¼ˆshape of $eï¼šM \times D_v$ï¼‰

$y_j = \sum_i a_{i,j} v_iï¼Œ j=1,2,...,M$

å¼•å…¥äº†key vectorä¸value vectoråï¼Œæˆ‘ä»¬å°±å¯ä»¥æ”¹å˜è¾“å‡ºçš„ç»´åº¦äº†ï¼Œè¿™ä½¿å¾—æ¨¡å‹æ›´åŠ çµæ´»ã€‚

![](./cs231-img/cva.png)


### Self-attention Layer
---

äº‹å®ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥ä»input vectorsè®¡ç®—å‡ºquery vectorsï¼Œä»è€Œå®šä¹‰ä¸€ä¸ªâ€œè‡ªæ³¨æ„åŠ›â€å±‚ã€‚(Self-attention)

é€šè¿‡FCå±‚ï¼Œæˆ‘ä»¬ä»input vectorsè®¡ç®—å‡ºquery vectors:

- Query vectors: $\mathbf{q} = xW_q$ï¼Œï¼ˆshape of $W_qï¼šD \times D_k$ï¼‰ï¼ˆshape of $qï¼šN \times D_k$ï¼‰

![](./cs231-img/self.png)

ç”±äºattentionæœºåˆ¶å¹¶ä¸å…³å¿ƒè¾“å…¥çš„é¡ºåºï¼Œå³æ‹¥æœ‰â€œç½®æ¢ç­‰å˜â€ï¼ˆ Permutation equivariantï¼‰çš„ç‰¹æ€§ï¼Œå€˜è‹¥æ›´æ¢è¾“å…¥å‘é‡çš„æ¬¡åºï¼Œåªæ˜¯ä¼šæ”¹å˜è¾“å‡ºçš„é¡ºåºï¼Œè€Œä¸ä¼šæ”¹å˜è¾“å‡ºçš„å†…å®¹ã€‚ä½†æ˜¾ç„¶ï¼Œè¾“å…¥ä¿¡æ¯çš„å‰åé¡ºåºå¯¹è¯­ä¹‰å½±å“æå¤§ã€‚

![](./cs231-img/aad.png)

![](./cs231-img/7777.png)


### Positional encoding
---

ä¸ºäº†å…·æœ‰ä½ç½®æ„ŸçŸ¥èƒ½åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¾“å…¥ä¸ä½ç½®ç¼–ç è¿æ¥èµ·æ¥

è€ŒPositional Encodingï¼ˆä½ç½®ç¼–ç ï¼‰æŠ€æœ¯é€šè¿‡ä¸ºæ¯ä¸ªå•è¯æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç¼–ç æ¥è¡¨ç¤ºå®ƒåœ¨åºåˆ—ä¸­çš„ä½ç½®ï¼Œè¿™æ ·æ¨¡å‹å°±èƒ½å¤Ÿç†è§£å•è¯åœ¨åºåˆ—ä¸­çš„ç›¸å¯¹ä½ç½®ã€‚


### Masked self-attention layer(æ©ç è‡ªæ³¨æ„åŠ›)
---

![](./cs231-img/mask.png)



### Multi-head self-attention layer
---
![](./cs231-img/fg.png)

### Image Captioning using Transformers
---
![](./cs231-img/33.png)

### The Transformer encoder block
---

![](./cs231-img/transf.png)
![](./cs231-img/nm.png)

### The Transformer decoder block
---

![](./cs231-img/000.png)
