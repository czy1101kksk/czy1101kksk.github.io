
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="BRIGHT_CZY">
      
      
        <link rel="canonical" href="https://czy1101kksk.github.io/python/d2l-chapter/chapter1/">
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>🔗Chapter 1：linear regression and multilayer perceptron - BRIGHT_CZY's site</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#chapter-1linear-regression-and-multilayer-perceptron" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="BRIGHT_CZY&#39;s site" class="md-header__button md-logo" aria-label="BRIGHT_CZY's site" data-md-component="logo">
      
  <img src="https://avatars.githubusercontent.com/u/122161543?s=400&u=203bce014a72777aa55f7a4d63a2c98df3bac6e2&v=4" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BRIGHT_CZY's site
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              🔗Chapter 1：linear regression and multilayer perceptron
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 1 3 3 3 3 0 0 1-3 3 3 3 0 0 1-3-3 3 3 0 0 1 3-3m0-4.5c5 0 9.27 3.11 11 7.5-1.73 4.39-6 7.5-11 7.5S2.73 16.39 1 12c1.73-4.39 6-7.5 11-7.5M3.18 12a9.821 9.821 0 0 0 17.64 0 9.821 9.821 0 0 0-17.64 0"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/czy1101kksk/czy1101kksk.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    BRIGHT_CZY/notebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BRIGHT_CZY&#39;s site" class="md-nav__button md-logo" aria-label="BRIGHT_CZY's site" data-md-component="logo">
      
  <img src="https://avatars.githubusercontent.com/u/122161543?s=400&u=203bce014a72777aa55f7a4d63a2c98df3bac6e2&v=4" alt="logo">

    </a>
    BRIGHT_CZY's site
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/czy1101kksk/czy1101kksk.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    BRIGHT_CZY/notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    🎆 主页
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            🎆 主页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🎆 主页
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📜 论文阅读
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            📜 论文阅读
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🍥 论文阅读主页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    DL论文
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            DL论文
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/EfficientNet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    EfficientNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/Attention-is-all-you-need/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention is all you need
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/Bert/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/MAE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MAE：Masked Autoencoders Are Scalable Vision Learners
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/ViT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ViT：An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/Distilling-the-knowledge/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distilling the Knowledge in a Neural Network
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/Noisy-students/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Self-training with Noisy Student improves ImageNet classification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/MoE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/cs/GAN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GAN：Generative Adversarial Nets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/ComputationalPhysics/Transovler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transolver: A Fast Transformer Solver for PDEs on General Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/ComputationalPhysics/AeroGTO/aerogto/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AeroGTO:An Efficient Graph-Transformer Operator for Learning Large-Scale Aerodynamics of 3D Vehicle Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/ComputationalPhysics/DeepONet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DeepONet: Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/ComputationalPhysics/FNO/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FNO: Fourier Neural Operator for Parametric Partial Differential Equations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/ComputationalPhysics/Transovler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transolver: A Fast Transformer Solver for PDEs on General Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/ComputationalPhysics/Transolver%2B%2B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transolver++: An Accurate Neural Solver for PDEs on Million-Scale Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📰综合能源系统
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            📰综合能源系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sci-paper/Load-Forecasting/%5BApplied%20Energy%5DA%20novel%20short-term%20multi-energy%20load%20forecasting%20method%20for%20integrated%20energy%20system%20based%20on%20feature%20separation-fusion%20technology%20and%20improved%20CNN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    [Applied Energy]A novel short-term multi-energy load forecasting method for integrated energy system based on feature separation-fusion technology and improved CNN
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    👨‍🎓 学习笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            👨‍🎓 学习笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../study-cs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🛠 课程学习主页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📑专业课程笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            📑专业课程笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../energy/Engineering_Thermodynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    工程热力学(甲)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Python-is-important/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔗Python校内课程笔记
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../energy/heat_transfer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    传热学
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cs224n-notebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🛣[Deep Learning]Stanford CS224n:Natural Language Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cs231n/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔭Stanford CS231n:Deep Learning for Computer Vision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cs224w/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔭Stanford CS224w:Machine Learning with Graphs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../d2l/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔭Dive into Deeplearing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../python-something/fluent-python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🛣 《流畅的Python》
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📊 杂项
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            📊 杂项
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/FFT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    快速傅里叶变换（FFT）
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/RBF/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    径向基函数(Radial basis function)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/GumbelSoftmax/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gumbel-Softmax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/TensorCalculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    张量分析：Tensor Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/HigherAlgebra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    高等代数：Higher Algebra 个人笔记
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    ✍ 施工中
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            ✍ 施工中
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../wait-for-me/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    施工中.....
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#线性回归" class="md-nav__link">
    <span class="md-ellipsis">
      线性回归
    </span>
  </a>
  
    <nav class="md-nav" aria-label="线性回归">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#线性回归的表示" class="md-nav__link">
    <span class="md-ellipsis">
      线性回归的表示
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#损失函数" class="md-nav__link">
    <span class="md-ellipsis">
      损失函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#随机梯度下降法" class="md-nav__link">
    <span class="md-ellipsis">
      随机梯度下降法
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#线性回归的解析解" class="md-nav__link">
    <span class="md-ellipsis">
      线性回归的解析解
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#线性回归的基础实现" class="md-nav__link">
    <span class="md-ellipsis">
      线性回归的基础实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#线性回归的简洁实现" class="md-nav__link">
    <span class="md-ellipsis">
      线性回归的简洁实现
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax回归" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax回归
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#softmax的简洁实现" class="md-nav__link">
    <span class="md-ellipsis">
      Softmax的简洁实现
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#多层感知机" class="md-nav__link">
    <span class="md-ellipsis">
      多层感知机
    </span>
  </a>
  
    <nav class="md-nav" aria-label="多层感知机">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#权重衰减" class="md-nav__link">
    <span class="md-ellipsis">
      权重衰减
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#暂退法dropout" class="md-nav__link">
    <span class="md-ellipsis">
      暂退法dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xavier初始化" class="md-nav__link">
    <span class="md-ellipsis">
      Xavier初始化
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="chapter-1linear-regression-and-multilayer-perceptron">🔗<B>Chapter 1：linear regression and multilayer perceptron</B><a class="headerlink" href="#chapter-1linear-regression-and-multilayer-perceptron" title="Permanent link"></a></h1>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<h2 id="线性回归">线性回归<a class="headerlink" href="#线性回归" title="Permanent link"></a></h2>
<hr />
<h3 id="线性回归的表示">线性回归的表示<a class="headerlink" href="#线性回归的表示" title="Permanent link"></a></h3>
<p>线性回归(linear regression)基于几个简单假设：</p>
<ul>
<li>
<p>自变量<span class="arithmatex">\(\mathbf{x}\)</span>与因变量<span class="arithmatex">\(y\)</span>之间的关系是线性的，即<span class="arithmatex">\(y\)</span>可以表示为<span class="arithmatex">\(\mathbf{x}\)</span>中元素的加权和:</p>
<div class="arithmatex">\[
    \hat{y} = \mathbf{w}^\intercal \mathbf{x} + b         
\]</div>
<p>对于多维数据<span class="arithmatex">\(\mathbf{X} \in \mathbb{R}^{n \times d}\)</span>，即n个样本，d种特征：</p>
<div class="arithmatex">\[
    {\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b
\]</div>
</li>
<li>
<p>允许观测值中存在噪声，假设任何噪声都比较正常，如噪声遵循正态分布。</p>
</li>
</ul>
<h3 id="损失函数">损失函数<a class="headerlink" href="#损失函数" title="Permanent link"></a></h3>
<p>对于真实样本数据集，其中的<span class="arithmatex">\(\mathbf{x}\)</span>与<span class="arithmatex">\(y\)</span>之间不可能具有标准的线性关系，因此需要一个<B>确定一个拟合程度的度量</B>,即损失函数（loss function），来<B>量化目标的实际值与预测值之间的差距</B>。对于回归问题通常使用平方误差函数（MSE）作为损失函数：</p>
<div class="arithmatex">\[
    L(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \left(\hat{y}^{(i)} - y^{(i)}\right)^2 =\frac{1}{n} \sum_{i=1}^n \left(\mathbf{w}^\intercal \mathbf{x}^{(i)} + b - y^{(i)}\right)^2
\]</div>
<p>即我们希望寻找到最优的权重与偏置<span class="arithmatex">\((\mathbf{w}^*, b^*) = \operatorname*{argmin}_{\mathbf{w}, b}\  L(\mathbf{w}, b)\)</span>，来使得总损失最小(与真实值的差距小)。</p>
<h3 id="随机梯度下降法">随机梯度下降法<a class="headerlink" href="#随机梯度下降法" title="Permanent link"></a></h3>
<p>梯度下降法（gradient descent）在损失函数减小的方向上更新参数来降低误差：</p>
<p><img alt="" src="../d2l-img/1.png" /></p>
<div class="arithmatex">\[
    (\mathbf{w},b) \leftarrow (\mathbf{w},b) - \eta \sum_{i =1}^n \partial_{(\mathbf{w},b)} l^{(i)}(\mathbf{w},b).   
\]</div>
<p>因为传统的梯度下降法需要遍历整个数据集，在实际的执行中可能会较慢，因此可以在每一次更新权重时随机抽取一小批样本来计算更新，这种变体为小批量随机梯度下降法(minibatch stochastic gradient descent),假设从数据集中随机抽取一个小批量<span class="arithmatex">\(\mathcal{B}\)</span>：</p>
<div class="arithmatex">\[
\begin{split}
\begin{aligned} 
\mathbf{w} &amp;\leftarrow \mathbf{w} -   \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b) = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right),    \\ 
b &amp;\leftarrow b -  \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_b l^{(i)}(\mathbf{w}, b)  = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right).  \\
\end{aligned}
\end{split}
\]</div>
<p>其中<span class="arithmatex">\(|\mathcal{B}|\)</span>为表示每个小批量中的样本数，即批量大小（batch size）</p>
<blockquote>
<p>即使数据集是完美符合线性且无噪声，通过梯度下降法得到的估计值也不会使损失函数真正地达到最小值：因为算法会使得损失向最小值缓慢收敛，但却不能在有限的步数内非常精确地达到最小值。</p>
</blockquote>
<h3 id="线性回归的解析解">线性回归的解析解<a class="headerlink" href="#线性回归的解析解" title="Permanent link"></a></h3>
<p>对于线性回归任务，我们的目标是最小化<span class="arithmatex">\(\|\mathbf{y} - \mathbf{X}\mathbf{w}\|^2\)</span>，对于<span class="arithmatex">\({\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b\)</span>：</p>
<div class="arithmatex">\[
    \begin{aligned}
    \|\mathbf{y} - \mathbf{X}\mathbf{w}\|^2 =&amp; (\mathbf{y} - \mathbf{X}\mathbf{w})^\intercal (\mathbf{y} - \mathbf{X}\mathbf{w}) =  (\mathbf{y}^\intercal - \mathbf{w}^\intercal \mathbf{X}^\intercal) (\mathbf{y} - \mathbf{X}\mathbf{w}) \\
    =&amp; \mathbf{y}^\intercal \mathbf{y} + \mathbf{w}^\intercal \mathbf{X}^\intercal \mathbf{X}\mathbf{w} - \mathbf{y}^\intercal \mathbf{X}\mathbf{w} - \mathbf{w}^\intercal \mathbf{X}^\intercal \mathbf{y} \\
    =&amp; \mathbf{y}^\intercal \mathbf{y} + \mathbf{w}^\intercal \mathbf{X}^\intercal \mathbf{X}\mathbf{w} - 2 \mathbf{y}^\intercal \mathbf{X}\mathbf{w} \\
    \end{aligned}      
\]</div>
<p>为求极值，使<span class="arithmatex">\(\nabla_{\mathbf{w}} \|\mathbf{y} - \mathbf{X}\mathbf{w}\|^2 = 0\)</span>,有：</p>
<div class="arithmatex">\[
    \nabla_{\mathbf{w}} \|\mathbf{y} - \mathbf{X}\mathbf{w}\|^2 = 2 \mathbf{X}^\intercal \mathbf{X}\mathbf{w} - 2 \mathbf{X}^\intercal \mathbf{y}    
\]</div>
<p>可得：</p>
<div class="arithmatex">\[
    \mathbf{w}^* = (\mathbf X^\intercal \mathbf X)^{-1}\mathbf X^\intercal \mathbf{y}    
\]</div>
<h3 id="线性回归的基础实现">线性回归的基础实现<a class="headerlink" href="#线性回归的基础实现" title="Permanent link"></a></h3>
<p>为了实现一个完整的线性回归模型，我们需要生成数据、构建模型、损失函数和小批量随机梯度下降优化器，本节来实现一个最基础的线性回归模型：</p>
<ul>
<li>生成一个带噪声的数据集</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">1</a></span>
<span class="normal"><a href="#__codelineno-0-2">2</a></span>
<span class="normal"><a href="#__codelineno-0-3">3</a></span>
<span class="normal"><a href="#__codelineno-0-4">4</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">CreatData</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="n">features</span><span class="p">))</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">))</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>构建线性回归模型以及损失函数</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-1-1">1</a></span>
<span class="normal"><a href="#__codelineno-1-2">2</a></span>
<span class="normal"><a href="#__codelineno-1-3">3</a></span>
<span class="normal"><a href="#__codelineno-1-4">4</a></span>
<span class="normal"><a href="#__codelineno-1-5">5</a></span>
<span class="normal"><a href="#__codelineno-1-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">LinearRegression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-1-2" name="__codelineno-1-2"></a>    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span> 
<a id="__codelineno-1-3" name="__codelineno-1-3"></a>    <span class="k">return</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> 
<a id="__codelineno-1-4" name="__codelineno-1-4"></a>
<a id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">MSELossfunction</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<a id="__codelineno-1-6" name="__codelineno-1-6"></a>    <span class="k">return</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>小批量随机梯度下降</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-2-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-2-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-2-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-2-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-2-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-2-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-2-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-2-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-2-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-2-10">10</a></span>
<span class="normal"><a href="#__codelineno-2-11">11</a></span>
<span class="normal"><a href="#__codelineno-2-12">12</a></span>
<span class="normal"><a href="#__codelineno-2-13">13</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">Dataiter_RandomBatch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>   <span class="c1"># 迭代器</span>
<a id="__codelineno-2-2" name="__codelineno-2-2"></a>    <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<a id="__codelineno-2-3" name="__codelineno-2-3"></a>    <span class="n">numlist</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num</span><span class="p">)]</span>
<a id="__codelineno-2-4" name="__codelineno-2-4"></a>    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">numlist</span><span class="p">)</span>
<a id="__codelineno-2-5" name="__codelineno-2-5"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<a id="__codelineno-2-6" name="__codelineno-2-6"></a>        <span class="n">RandomBatch</span> <span class="o">=</span> <span class="n">numlist</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num</span><span class="p">)]</span>
<a id="__codelineno-2-7" name="__codelineno-2-7"></a>        <span class="k">yield</span> <span class="n">features</span><span class="p">[</span><span class="n">RandomBatch</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">RandomBatch</span><span class="p">]</span>
<a id="__codelineno-2-8" name="__codelineno-2-8"></a>
<a id="__codelineno-2-9" name="__codelineno-2-9"></a><span class="k">def</span><span class="w"> </span><span class="nf">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
<a id="__codelineno-2-10" name="__codelineno-2-10"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-2-11" name="__codelineno-2-11"></a>        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
<a id="__codelineno-2-12" name="__codelineno-2-12"></a>            <span class="n">param</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">/</span> <span class="n">batch_size</span>
<a id="__codelineno-2-13" name="__codelineno-2-13"></a>            <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>程序主体</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-3-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-3-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-3-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-3-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-3-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-3-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-3-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-3-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-3-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-3-10">10</a></span>
<span class="normal"><a href="#__codelineno-3-11">11</a></span>
<span class="normal"><a href="#__codelineno-3-12">12</a></span>
<span class="normal"><a href="#__codelineno-3-13">13</a></span>
<span class="normal"><a href="#__codelineno-3-14">14</a></span>
<span class="normal"><a href="#__codelineno-3-15">15</a></span>
<span class="normal"><a href="#__codelineno-3-16">16</a></span>
<span class="normal"><a href="#__codelineno-3-17">17</a></span>
<span class="normal"><a href="#__codelineno-3-18">18</a></span>
<span class="normal"><a href="#__codelineno-3-19">19</a></span>
<span class="normal"><a href="#__codelineno-3-20">20</a></span>
<span class="normal"><a href="#__codelineno-3-21">21</a></span>
<span class="normal"><a href="#__codelineno-3-22">22</a></span>
<span class="normal"><a href="#__codelineno-3-23">23</a></span>
<span class="normal"><a href="#__codelineno-3-24">24</a></span>
<span class="normal"><a href="#__codelineno-3-25">25</a></span>
<span class="normal"><a href="#__codelineno-3-26">26</a></span>
<span class="normal"><a href="#__codelineno-3-27">27</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="n">w_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<a id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="n">b_0</span> <span class="o">=</span> <span class="mf">5.5</span>
<a id="__codelineno-3-3" name="__codelineno-3-3"></a>
<a id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="n">num_examples</span> <span class="o">=</span> <span class="mi">100</span> 
<a id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="n">features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">w_0</span><span class="p">)</span>
<a id="__codelineno-3-6" name="__codelineno-3-6"></a>
<a id="__codelineno-3-7" name="__codelineno-3-7"></a><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">CreatData</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">,</span> <span class="n">w_0</span><span class="p">,</span> <span class="n">b_0</span><span class="p">)</span>
<a id="__codelineno-3-8" name="__codelineno-3-8"></a>
<a id="__codelineno-3-9" name="__codelineno-3-9"></a><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">w_0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-3-10" name="__codelineno-3-10"></a><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-3-11" name="__codelineno-3-11"></a>
<a id="__codelineno-3-12" name="__codelineno-3-12"></a><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<a id="__codelineno-3-13" name="__codelineno-3-13"></a><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
<a id="__codelineno-3-14" name="__codelineno-3-14"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<a id="__codelineno-3-15" name="__codelineno-3-15"></a>
<a id="__codelineno-3-16" name="__codelineno-3-16"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>    
<a id="__codelineno-3-17" name="__codelineno-3-17"></a>    <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">Dataiter_RandomBatch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<a id="__codelineno-3-18" name="__codelineno-3-18"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">MSELossfunction</span><span class="p">(</span><span class="n">y_batch</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<a id="__codelineno-3-19" name="__codelineno-3-19"></a>        <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-3-20" name="__codelineno-3-20"></a>        <span class="n">SGD</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  
<a id="__codelineno-3-21" name="__codelineno-3-21"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-3-22" name="__codelineno-3-22"></a>        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">MSELossfunction</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<a id="__codelineno-3-23" name="__codelineno-3-23"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_loss</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-3-24" name="__codelineno-3-24"></a>
<a id="__codelineno-3-25" name="__codelineno-3-25"></a>
<a id="__codelineno-3-26" name="__codelineno-3-26"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;w的估计误差: </span><span class="si">{</span><span class="n">w_0</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">w</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-3-27" name="__codelineno-3-27"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;b的估计误差: </span><span class="si">{</span><span class="n">b_0</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">b</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="admonition advice">
<p class="admonition-title">对于loss.sum().backward()的理解</p>
<p><font size = 3>
出处： <a href="https://zhuanlan.zhihu.com/p/427853673">https://zhuanlan.zhihu.com/p/427853673</a></p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-4-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-4-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-4-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-4-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-4-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-4-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-4-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-4-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-4-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-4-10">10</a></span>
<span class="normal"><a href="#__codelineno-4-11">11</a></span>
<span class="normal"><a href="#__codelineno-4-12">12</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
<a id="__codelineno-4-2" name="__codelineno-4-2"></a>    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<a id="__codelineno-4-3" name="__codelineno-4-3"></a>        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># `X`和`y`的小批量损失</span>
<a id="__codelineno-4-4" name="__codelineno-4-4"></a>        <span class="c1"># 因为`l`形状是(`batch_size`, 1)，而不是一个标量。`l`中的所有元素被加到一起，</span>
<a id="__codelineno-4-5" name="__codelineno-4-5"></a>        <span class="c1"># 并以此计算关于[`w`, `b`]的梯度</span>
<a id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="o">--------------------------------------------------------------</span>
<a id="__codelineno-4-7" name="__codelineno-4-7"></a>        <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-4-8" name="__codelineno-4-8"></a><span class="o">--------------------------------------------------------------</span>
<a id="__codelineno-4-9" name="__codelineno-4-9"></a>        <span class="n">sgd</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># 使用参数的梯度更新参数</span>
<a id="__codelineno-4-10" name="__codelineno-4-10"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-4-11" name="__codelineno-4-11"></a>        <span class="n">train_l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
<a id="__codelineno-4-12" name="__codelineno-4-12"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
如果Tensor 是一个标量(即它包含一个元素的数据)，则不需要为 backward() 指定任何参数，但是如果它有更多的元素，则需要指定一个 gradient 参数，该参数是形状匹配的张量。本代码中l为矩阵，需要l.sum()转化为标量后再.backward()。</p>
<p></font></p>
</div>
<div class="admonition info">
<p class="admonition-title">pytorch中自加（+=）与普通加的区别</p>
<p><font size = 3>
出处： <a href="https://blog.csdn.net/senbinyu/article/details/102634505">https://blog.csdn.net/senbinyu/article/details/102634505</a></p>
<p>讨论pytorch中x= x + a 与 x += a（自加）的区别，在于内存地址</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-5-1">1</a></span>
<span class="normal"><a href="#__codelineno-5-2">2</a></span>
<span class="normal"><a href="#__codelineno-5-3">3</a></span>
<span class="normal"><a href="#__codelineno-5-4">4</a></span>
<span class="normal"><a href="#__codelineno-5-5">5</a></span>
<span class="normal"><a href="#__codelineno-5-6">6</a></span>
<span class="normal"><a href="#__codelineno-5-7">7</a></span>
<span class="normal"><a href="#__codelineno-5-8">8</a></span>
<span class="normal"><a href="#__codelineno-5-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<a id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="n">id_a</span> <span class="o">=</span> <span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<a id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="n">a</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-5-4" name="__codelineno-5-4"></a>
<a id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="n">id_a</span>  <span class="c1">#---&gt; True</span>
<a id="__codelineno-5-6" name="__codelineno-5-6"></a>
<a id="__codelineno-5-7" name="__codelineno-5-7"></a><span class="n">a</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span>
<a id="__codelineno-5-8" name="__codelineno-5-8"></a>
<a id="__codelineno-5-9" name="__codelineno-5-9"></a><span class="nb">id</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">==</span> <span class="n">id_a</span>  <span class="c1">#---&gt; False</span>
</code></pre></div></td></tr></table></div>
<p>为了方便进行原位操作，Pytorch中的函数可以在调用之后加下划线 ，强调这是进行原位操作
</font></p>
</div>
<h3 id="线性回归的简洁实现">线性回归的简洁实现<a class="headerlink" href="#线性回归的简洁实现" title="Permanent link"></a></h3>
<ul>
<li>定义模型以及数据集迭代器，初始化模型参数</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-6-1">1</a></span>
<span class="normal"><a href="#__codelineno-6-2">2</a></span>
<span class="normal"><a href="#__codelineno-6-3">3</a></span>
<span class="normal"><a href="#__codelineno-6-4">4</a></span>
<span class="normal"><a href="#__codelineno-6-5">5</a></span>
<span class="normal"><a href="#__codelineno-6-6">6</a></span>
<span class="normal"><a href="#__codelineno-6-7">7</a></span>
<span class="normal"><a href="#__codelineno-6-8">8</a></span>
<span class="normal"><a href="#__codelineno-6-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="n">dataset</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<a id="__codelineno-6-2" name="__codelineno-6-2"></a><span class="n">dataLoader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-6-3" name="__codelineno-6-3"></a>
<a id="__codelineno-6-4" name="__codelineno-6-4"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-6-5" name="__codelineno-6-5"></a><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<a id="__codelineno-6-6" name="__codelineno-6-6"></a><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-6-7" name="__codelineno-6-7"></a>
<a id="__codelineno-6-8" name="__codelineno-6-8"></a><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<a id="__codelineno-6-9" name="__codelineno-6-9"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.03</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>训练过程</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-7-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-7-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-7-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-7-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-7-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-7-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-7-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-7-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-7-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-7-10">10</a></span>
<span class="normal"><a href="#__codelineno-7-11">11</a></span>
<span class="normal"><a href="#__codelineno-7-12">12</a></span>
<span class="normal"><a href="#__codelineno-7-13">13</a></span>
<span class="normal"><a href="#__codelineno-7-14">14</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<a id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
<a id="__codelineno-7-3" name="__codelineno-7-3"></a>    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataLoader</span><span class="p">:</span>
<a id="__codelineno-7-4" name="__codelineno-7-4"></a>        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="p">,</span><span class="n">y</span><span class="p">)</span>
<a id="__codelineno-7-5" name="__codelineno-7-5"></a>        <span class="n">trainer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1">#清除上一次的梯度值 </span>
<a id="__codelineno-7-6" name="__codelineno-7-6"></a>        <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1">#损失函数进行反向传播 求参数的梯度</span>
<a id="__codelineno-7-7" name="__codelineno-7-7"></a>        <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1">#步进 根据指定的优化算法进行参数更新</span>
<a id="__codelineno-7-8" name="__codelineno-7-8"></a>    <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
<a id="__codelineno-7-9" name="__codelineno-7-9"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">, loss </span><span class="si">{</span><span class="n">l</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-7-10" name="__codelineno-7-10"></a>
<a id="__codelineno-7-11" name="__codelineno-7-11"></a><span class="n">w</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
<a id="__codelineno-7-12" name="__codelineno-7-12"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;w的估计误差：&#39;</span><span class="p">,</span> <span class="n">true_w</span> <span class="o">-</span> <span class="n">w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">true_w</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<a id="__codelineno-7-13" name="__codelineno-7-13"></a><span class="n">b</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
<a id="__codelineno-7-14" name="__codelineno-7-14"></a><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b的估计误差：&#39;</span><span class="p">,</span> <span class="n">true_b</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="admonition advice">
<p class="admonition-title">如果我们用nn.MSELoss(reduction=‘sum’)替换nn.MSELoss()代码的行为相同，需要怎么更改学习速率？</p>
<p><font size = 3>
需要将学习率lr除以batch_size(默认参数是'mean')</p>
<p>原因：若损失函数采用'sum' ，等效于损失函数相对于'mean'放大，将会使得计算所得的梯度增大,这时候原有的学习率显得过大，无法高效逼近最优点。</p>
<p></font></p>
</div>
<div class="admonition advice">
<p class="admonition-title">如果我们将权重初始化为零，会发生什么。算法仍然有效吗？</p>
<p><font size = 3>
参考文章：<a href="https://zhuanlan.zhihu.com/p/75879624">谈谈神经网络权重为什么不能初始化为0</a></p>
<p>在单层网络中(一层线性回归层)，可以把权重初始化为0，但是当网络加深后，在全连接的情况下，在反向传播的时候，由于<B>权重的对称性</B>会导致出现隐藏神经元的对称性，使得多个隐藏神经元的作用就如同1个神经元，算法还是有效的，但是效果不大好。</p>
<p></font></p>
</div>
<h3 id="softmax回归">Softmax回归<a class="headerlink" href="#softmax回归" title="Permanent link"></a></h3>
<p>在分类问题当中，我们需要得到每个类别的概率（因此有多个输出）,我们希望模型的输出<span class="arithmatex">\(\hat{y}_j\)</span>可以视为属于类<span class="arithmatex">\(j\)</span>的概率，然后选择具有最大输出值的类别<span class="arithmatex">\(\operatorname*{argmax} y_j\)</span>作为我们的预测。 </p>
<p>例如，如果<span class="arithmatex">\(\hat{y}_1\)</span>、<span class="arithmatex">\(\hat{y}_2\)</span>和<span class="arithmatex">\(\hat{y}_3\)</span>分别为0.1、0.8和0.1， 那么我们预测的类别就是第2类。因此，我们要将多个输出数字的总和限制为1，并且每个输出永远大于0，</p>
<p><B>softmax函数</B>能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质(规范化)。</p>
<div class="arithmatex">\[
    \hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o})\quad \text{其中} \quad 0 \leq \hat{y}_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}  \leq 1  
\]</div>
<p>在小批量样本处理中，其中特征维度（输入数量）为d，批量大小为n，输出为q，假设小批量样本的特征为<span class="arithmatex">\(\mathbf{X} \in \mathbb{R}^{n \times d}\)</span>，权重矩阵为<span class="arithmatex">\(\mathbf{W} \in \mathbb{R}^{d \times q}\)</span>，偏置为<span class="arithmatex">\(\mathbf{b} \in \mathbb{R}^{1\times q}\)</span>，则softmax回归可表示为：</p>
<div class="arithmatex">\[
   \begin{split}
   \begin{aligned} 
   \mathbf{O} &amp;= \mathbf{X} \mathbf{W} + \mathbf{b}, \\ 
   \hat{\mathbf{Y}} &amp; = \mathrm{softmax}(\mathbf{O}). 
   \end{aligned}
   \end{split} 
\]</div>
<p>由上述易知，<span class="arithmatex">\(\hat{\mathbf{y}}\)</span>可理解为<B>对给定任意输入
<span class="arithmatex">\(\mathbf{x}\)</span>的属于每个类的条件概率</B>。对于softmax回归，我们可以使用<span class="arithmatex">\(\|\boldsymbol{\hat y}^{(i)}-\boldsymbol{y}^{(i)}\|^2/2\)</span>，但实际上并<B>不需要预测概率与标签概率完全相同</B>,只需要对应的<span class="arithmatex">\(\hat{\mathbf{y}}^{(i)}\)</span>比其他类别大即可。</p>
<p>对于数据集<span class="arithmatex">\(\{\mathbf{X}, \mathbf{Y}\}\)</span>具有n个样本，有：</p>
<div class="arithmatex">\[
   P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}). 
\]</div>
<p>要最大化<span class="arithmatex">\(P(\mathbf{Y} \mid \mathbf{X})\)</span>,向上式做负对数化:</p>
<div class="arithmatex">\[
    -\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)})
= \sum_{i=1}^n H (\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)})    
\]</div>
<p>其中：</p>
<div class="arithmatex">\[
    H (\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)}
\]</div>
<p>上式这个损失函数被称为交叉熵损失（cross-entropy loss）,因为向量<span class="arithmatex">\(\boldsymbol y^{(i)}\)</span>只有其中的某一个元素为1，其余均为0,即<B>交叉熵只关心对正确类别的预测概率，因为只要其值足够大，就可以确保分类结果正确</B></p>
<p>假设训练数据集的样本数为 n，交叉熵损失函数定义为:</p>
<div class="arithmatex">\[
    \ell(\boldsymbol{\Theta}) = \frac{1}{n} \sum_{i=1}^n H (\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)})        
\]</div>
<p>根据softmax的定义，可知其导数：</p>
<div class="arithmatex">\[
\partial_{o_j} l(\mathbf{y}, \hat{\mathbf{y}}) = \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} - y_j = \mathrm{softmax}(\mathbf{o})_j - y_j. 
\]</div>
<p>该导数即是softmax模型分配的概率与实际发生的情况之间的差异，这使梯度计算在实践中变得容易很多。</p>
<div class="admonition advice">
<p class="admonition-title">Advice</p>
<p><font size = 3>
对上式<span class="arithmatex">\(H (\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)}) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)}\)</span>的解答：
<img alt="" src="../d2l-img/softmax.png" /></p>
<p></font></p>
</div>
<div class="admonition info">
<p class="admonition-title">基于数学定义的softmax函数可能导致什么问题？提示：尝试计算exp(50)的大小。</p>
<p><font size = 3></p>
<p>可能会导致数据溢出的情况。可以使用LogSoftmax代替，即在Softmax的基础上再做一次log。(nn.LogSoftmax())</p>
<div class="arithmatex">\[
    LogSoftmax(x_i) = log(\frac{exp(x_i)}{\sum_j exp(x_j)})    
\]</div>
<p><B>LogSoftmax相对于Softmax的优势</B></p>
<ul>
<li>
<p>对数运算时求导更容易，加快了反向传播的速度。</p>
</li>
<li>
<p>解决Softmax可能存在的上溢和下溢的问题。</p>
</li>
</ul>
<p></font></p>
</div>
<div class="admonition advice">
<p class="admonition-title">pytorch中的nn.CrossEntropyLoss()</p>
<p><font size = 3></p>
<p>先说负对数似然函数NLLLoss()，本质上就是一种交叉熵函数：</p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-8-1">1</a></span>
<span class="normal"><a href="#__codelineno-8-2">2</a></span>
<span class="normal"><a href="#__codelineno-8-3">3</a></span>
<span class="normal"><a href="#__codelineno-8-4">4</a></span>
<span class="normal"><a href="#__codelineno-8-5">5</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1"></a><span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-8-2" name="__codelineno-8-2"></a>                    <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-8-3" name="__codelineno-8-3"></a><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-8-4" name="__codelineno-8-4"></a><span class="n">nn</span><span class="o">.</span><span class="n">nllloss</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<a id="__codelineno-8-5" name="__codelineno-8-5"></a><span class="c1"># output: tensor(-7)</span>
</code></pre></div></td></tr></table></div>
即在使用NLLLoss前要先使用LogSoftmax</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-9-1">1</a></span>
<span class="normal"><a href="#__codelineno-9-2">2</a></span>
<span class="normal"><a href="#__codelineno-9-3">3</a></span>
<span class="normal"><a href="#__codelineno-9-4">4</a></span>
<span class="normal"><a href="#__codelineno-9-5">5</a></span>
<span class="normal"><a href="#__codelineno-9-6">6</a></span>
<span class="normal"><a href="#__codelineno-9-7">7</a></span>
<span class="normal"><a href="#__codelineno-9-8">8</a></span>
<span class="normal"><a href="#__codelineno-9-9">9</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1"></a><span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-9-2" name="__codelineno-9-2"></a>                    <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-9-3" name="__codelineno-9-3"></a><span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
<a id="__codelineno-9-4" name="__codelineno-9-4"></a><span class="c1"># predict: tensor([[-1.4076, -0.4076, -2.4076],</span>
<a id="__codelineno-9-5" name="__codelineno-9-5"></a>                   <span class="p">[</span><span class="o">-</span><span class="mf">6.1291</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.1291</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1291</span><span class="p">]])</span>
<a id="__codelineno-9-6" name="__codelineno-9-6"></a>
<a id="__codelineno-9-7" name="__codelineno-9-7"></a><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-9-8" name="__codelineno-9-8"></a><span class="n">nllloss</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<a id="__codelineno-9-9" name="__codelineno-9-9"></a><span class="c1"># output: tensor(0.2684)</span>
</code></pre></div></td></tr></table></div>
<p><B>nn.CrossEntropyLoss()损失函数</B></p>
<div class="arithmatex">\[
    CrossEntropyLoss() = NLLLoss(LogSoftmax())    
\]</div>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-10-1">1</a></span>
<span class="normal"><a href="#__codelineno-10-2">2</a></span>
<span class="normal"><a href="#__codelineno-10-3">3</a></span>
<span class="normal"><a href="#__codelineno-10-4">4</a></span>
<span class="normal"><a href="#__codelineno-10-5">5</a></span>
<span class="normal"><a href="#__codelineno-10-6">6</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="n">cross_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<a id="__codelineno-10-2" name="__codelineno-10-2"></a><span class="n">predict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<a id="__codelineno-10-3" name="__codelineno-10-3"></a>                        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<a id="__codelineno-10-4" name="__codelineno-10-4"></a><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<a id="__codelineno-10-5" name="__codelineno-10-5"></a><span class="n">cross_loss</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
<a id="__codelineno-10-6" name="__codelineno-10-6"></a><span class="c1"># output: tensor(0.2684)</span>
</code></pre></div></td></tr></table></div>
<p></font></p>
</div>
<h3 id="softmax的简洁实现">Softmax的简洁实现<a class="headerlink" href="#softmax的简洁实现" title="Permanent link"></a></h3>
<ul>
<li>使用pytorch内置的Fashion-MNIST分类数据集</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-11-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-11-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-11-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-11-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-11-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-11-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-11-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-11-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-11-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-11-10">10</a></span>
<span class="normal"><a href="#__codelineno-11-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1"></a><span class="n">mnist_train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
<a id="__codelineno-11-2" name="__codelineno-11-2"></a>    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;../data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-11-3" name="__codelineno-11-3"></a><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
<a id="__codelineno-11-4" name="__codelineno-11-4"></a>    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;../data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-11-5" name="__codelineno-11-5"></a>
<a id="__codelineno-11-6" name="__codelineno-11-6"></a><span class="c1"># Fashion-MNIST由10个类别的图像组成,每个类别由训练数据集中的6000张图像和测试数据集中的1000张图像组成.</span>
<a id="__codelineno-11-7" name="__codelineno-11-7"></a>
<a id="__codelineno-11-8" name="__codelineno-11-8"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
<a id="__codelineno-11-9" name="__codelineno-11-9"></a>
<a id="__codelineno-11-10" name="__codelineno-11-10"></a><span class="n">train_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-11-11" name="__codelineno-11-11"></a><span class="n">test_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>设置网络，并且使用.apply()技巧对多层网络进行参数初始化</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-12-1">1</a></span>
<span class="normal"><a href="#__codelineno-12-2">2</a></span>
<span class="normal"><a href="#__codelineno-12-3">3</a></span>
<span class="normal"><a href="#__codelineno-12-4">4</a></span>
<span class="normal"><a href="#__codelineno-12-5">5</a></span>
<span class="normal"><a href="#__codelineno-12-6">6</a></span>
<span class="normal"><a href="#__codelineno-12-7">7</a></span>
<span class="normal"><a href="#__codelineno-12-8">8</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>   <span class="c1">#权重初始化。apply()</span>
<a id="__codelineno-12-2" name="__codelineno-12-2"></a>    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
<a id="__codelineno-12-3" name="__codelineno-12-3"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-12-4" name="__codelineno-12-4"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-12-5" name="__codelineno-12-5"></a>
<a id="__codelineno-12-6" name="__codelineno-12-6"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> 
<a id="__codelineno-12-7" name="__codelineno-12-7"></a>                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<a id="__codelineno-12-8" name="__codelineno-12-8"></a><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>设置优化器与损失函数</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-13-1">1</a></span>
<span class="normal"><a href="#__codelineno-13-2">2</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<a id="__codelineno-13-2" name="__codelineno-13-2"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>进行反向传播,计算分类准确度</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-14-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-14-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-14-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-14-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-14-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-14-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-14-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-14-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-14-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-14-10">10</a></span>
<span class="normal"><a href="#__codelineno-14-11">11</a></span>
<span class="normal"><a href="#__codelineno-14-12">12</a></span>
<span class="normal"><a href="#__codelineno-14-13">13</a></span>
<span class="normal"><a href="#__codelineno-14-14">14</a></span>
<span class="normal"><a href="#__codelineno-14-15">15</a></span>
<span class="normal"><a href="#__codelineno-14-16">16</a></span>
<span class="normal"><a href="#__codelineno-14-17">17</a></span>
<span class="normal"><a href="#__codelineno-14-18">18</a></span>
<span class="normal"><a href="#__codelineno-14-19">19</a></span>
<span class="normal"><a href="#__codelineno-14-20">20</a></span>
<span class="normal"><a href="#__codelineno-14-21">21</a></span>
<span class="normal"><a href="#__codelineno-14-22">22</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">iter</span><span class="p">):</span>
<a id="__codelineno-14-2" name="__codelineno-14-2"></a>    <span class="n">cmp</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-14-3" name="__codelineno-14-3"></a>    <span class="n">tot</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-14-4" name="__codelineno-14-4"></a>    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># 将模型设置为评估模式</span>
<a id="__codelineno-14-5" name="__codelineno-14-5"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-14-6" name="__codelineno-14-6"></a>        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">:</span>
<a id="__codelineno-14-7" name="__codelineno-14-7"></a>            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<a id="__codelineno-14-8" name="__codelineno-14-8"></a>            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 在行中比较，选出最大的列索引</span>
<a id="__codelineno-14-9" name="__codelineno-14-9"></a>            <span class="n">CountMatrix</span> <span class="o">=</span> <span class="n">y_hat</span> <span class="o">==</span> <span class="n">y</span>
<a id="__codelineno-14-10" name="__codelineno-14-10"></a>            <span class="n">cmp</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">CountMatrix</span><span class="p">)</span>
<a id="__codelineno-14-11" name="__codelineno-14-11"></a>            <span class="n">tot</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">CountMatrix</span><span class="p">)</span>
<a id="__codelineno-14-12" name="__codelineno-14-12"></a>    <span class="k">return</span> <span class="n">cmp</span> <span class="o">/</span> <span class="n">tot</span>
<a id="__codelineno-14-13" name="__codelineno-14-13"></a>
<a id="__codelineno-14-14" name="__codelineno-14-14"></a><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<a id="__codelineno-14-15" name="__codelineno-14-15"></a>
<a id="__codelineno-14-16" name="__codelineno-14-16"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
<a id="__codelineno-14-17" name="__codelineno-14-17"></a>    <span class="k">for</span> <span class="n">X_train</span> <span class="p">,</span> <span class="n">y_train</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
<a id="__codelineno-14-18" name="__codelineno-14-18"></a>        <span class="n">l</span> <span class="o">=</span><span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>
<a id="__codelineno-14-19" name="__codelineno-14-19"></a>        <span class="n">trainer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-14-20" name="__codelineno-14-20"></a>        <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-14-21" name="__codelineno-14-21"></a>        <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-14-22" name="__codelineno-14-22"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epoch</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">-accuracy:</span><span class="si">{</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">train_iter</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h2 id="多层感知机">多层感知机<a class="headerlink" href="#多层感知机" title="Permanent link"></a></h2>
<p>多层感知机（multilayer perceptron）通过在网络中加入一个或多个隐藏层来克服线性模型的限制，使其能处理更普遍的函数关系类型</p>
<h3 id="权重衰减">权重衰减<a class="headerlink" href="#权重衰减" title="Permanent link"></a></h3>
<p>在训练参数化机器学习模型时， 权重衰减（weight decay）是最广泛使用的正则化的技术之一， 它通常也被称为<span class="arithmatex">\(L_2\)</span>正则化。将<span class="arithmatex">\(L_2\)</span>范数作为惩罚项加到最小化损失的问题中,原来的训练目标最小化训练标签上的预测损失为最小化预测损失和惩罚项之和。如果权重向量增长过大，算法可能会更集中于最小化权重范数<span class="arithmatex">\(\| \mathbf{w} \|^2\)</span>
。</p>
<div class="arithmatex">\[
    L(\mathbf{w}, b) + \frac{\lambda}{2} \|\mathbf{w}\|^2,    
\]</div>
<ul>
<li>实现：</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-15-1">1</a></span>
<span class="normal"><a href="#__codelineno-15-2">2</a></span>
<span class="normal"><a href="#__codelineno-15-3">3</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
<a id="__codelineno-15-2" name="__codelineno-15-2"></a>        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">Lambda</span><span class="p">},</span>  <span class="c1"># 通过&#39;weight_decay&#39;设置权重的L2范数作为惩罚项</span>
<a id="__codelineno-15-3" name="__codelineno-15-3"></a>        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span><span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">}],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="暂退法dropout">暂退法dropout<a class="headerlink" href="#暂退法dropout" title="Permanent link"></a></h3>
<p>在标准暂退法正则化中，通过按保留（未丢弃）的节点的分数进行规范化来消除每一层的偏差。 换言之，每个中间活性值h以暂退概率p由随机变量替换h'，如下所示：</p>
<div class="arithmatex">\[
    \begin{split}
    \begin{aligned}
    h' =
    \begin{cases}
    0 &amp; \text{ 概率为 } p \\
    \frac{h}{1-p} &amp; \text{ 其他情况}
    \end{cases}
    \end{aligned}
    \end{split}    
\]</div>
<ul>
<li>dropout基础实现</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-16-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-16-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-16-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-16-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-16-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-16-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-16-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-16-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-16-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-16-10">10</a></span>
<span class="normal"><a href="#__codelineno-16-11">11</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">dropout_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
<a id="__codelineno-16-2" name="__codelineno-16-2"></a>    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">dropout</span> <span class="o">&lt;=</span> <span class="mi">1</span>
<a id="__codelineno-16-3" name="__codelineno-16-3"></a>
<a id="__codelineno-16-4" name="__codelineno-16-4"></a>    <span class="k">if</span> <span class="n">dropout</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span><span class="c1"># 在本情况中，所有元素都被丢弃</span>
<a id="__codelineno-16-5" name="__codelineno-16-5"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<a id="__codelineno-16-6" name="__codelineno-16-6"></a>
<a id="__codelineno-16-7" name="__codelineno-16-7"></a>    <span class="k">if</span> <span class="n">dropout</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span><span class="c1"># 在本情况中，所有元素都被保留</span>
<a id="__codelineno-16-8" name="__codelineno-16-8"></a>        <span class="k">return</span> <span class="n">X</span>
<a id="__codelineno-16-9" name="__codelineno-16-9"></a>
<a id="__codelineno-16-10" name="__codelineno-16-10"></a>    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">dropout</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<a id="__codelineno-16-11" name="__codelineno-16-11"></a>    <span class="k">return</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">dropout</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>简洁实现</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-17-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-17-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-17-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-17-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-17-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-17-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-17-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-17-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-17-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-17-10">10</a></span>
<span class="normal"><a href="#__codelineno-17-11">11</a></span>
<span class="normal"><a href="#__codelineno-17-12">12</a></span>
<span class="normal"><a href="#__codelineno-17-13">13</a></span>
<span class="normal"><a href="#__codelineno-17-14">14</a></span>
<span class="normal"><a href="#__codelineno-17-15">15</a></span>
<span class="normal"><a href="#__codelineno-17-16">16</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1"></a><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
<a id="__codelineno-17-2" name="__codelineno-17-2"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<a id="__codelineno-17-3" name="__codelineno-17-3"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<a id="__codelineno-17-4" name="__codelineno-17-4"></a>        <span class="c1"># 在第一个全连接层之后添加一个dropout层</span>
<a id="__codelineno-17-5" name="__codelineno-17-5"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout1</span><span class="p">),</span>
<a id="__codelineno-17-6" name="__codelineno-17-6"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<a id="__codelineno-17-7" name="__codelineno-17-7"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<a id="__codelineno-17-8" name="__codelineno-17-8"></a>        <span class="c1"># 在第二个全连接层之后添加一个dropout层</span>
<a id="__codelineno-17-9" name="__codelineno-17-9"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout2</span><span class="p">),</span>
<a id="__codelineno-17-10" name="__codelineno-17-10"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<a id="__codelineno-17-11" name="__codelineno-17-11"></a>
<a id="__codelineno-17-12" name="__codelineno-17-12"></a><span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<a id="__codelineno-17-13" name="__codelineno-17-13"></a>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<a id="__codelineno-17-14" name="__codelineno-17-14"></a>        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<a id="__codelineno-17-15" name="__codelineno-17-15"></a>
<a id="__codelineno-17-16" name="__codelineno-17-16"></a><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">);</span>
</code></pre></div></td></tr></table></div>
<p>总结：</p>
<ul>
<li>
<p>暂退法在前向传播过程中，计算每一内部层的同时丢弃一些神经元。</p>
</li>
<li>
<p>暂退法可以避免过拟合，它通常与控制权重向量的维数和大小结合使用的。</p>
</li>
</ul>
<div class="admonition advice">
<p class="admonition-title">如果更改第一层和第二层的暂退法概率,会发生什么情况?</p>
<p><font size = 3>
第一层暂退法概率大,第二层暂退法概率小,则效果会较好。</p>
<p>可能原因:</p>
<ul>
<li>
<p>前面层抽取的是比较底层的信息,有较多的无用信息冗余通过强神经元,从而使得网络记住这些冗余信息而学不到关键信息(导致过拟合),用较大Dropout较好,后面层主管高层抽象语义信息,较为关键,是把握识别整体的关键部分,用较小Dropout较好;</p>
</li>
<li>
<p>一般前面层全连接数目比较大,抽取信息量比较多,自然带来冗余信息较多,那么多的数目连接,可以通过较大Dropout丢弃掉大部分的全连接</p>
</li>
</ul>
<p>因此dropout能够减小网络对某些强神经元的依赖性，使得强弱神经元方差减小</p>
<p></font></p>
</div>
<h3 id="xavier初始化">Xavier初始化<a class="headerlink" href="#xavier初始化" title="Permanent link"></a></h3>
<p>Xavier初始化是一种在训练深度学习模型时常用的权重初始化方法。它是 Xavier Glorot 和 Yoshua Bengio 在 2010 年提出的，原文为 <a href="https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a>。该初始化方法旨在保持激活函数的方差在前向传播和反向传播过程中大致相同，从而避免梯度消失或梯度爆炸的问题。如果方差过大，那么网络的层将会更难以学习；如果方差过小，那么该层的权重将会难以更新。</p>
<blockquote>
<p>(xavier初始化只适用于关于0对称、呈线性的激活函数，比如 sigmoid、tanh)</p>
</blockquote>
<div class="admonition info">
<p class="admonition-title">梯度消失和爆炸</p>
<p><font size = 3>
在深度网络中，梯度消失和梯度爆炸是一个常见的问题。如果每一层都将方差放大，那么在多层网络中，梯度可能会很快增长至非常大的值（爆炸），或者减小至接近零（消失）。</p>
<p>Xavier 初始化试图使得每一层的输出的方差接近于其输入的方差，从而避免梯度消失或梯度爆炸的问题，每一层的参数更新的幅度就不会相差太大，从而加速收敛。</p>
<p></font></p>
</div>
<ul>
<li><code>torch.nn.init.xavier_uniform_</code> 函数从均匀分布中抽取权重，其中:</li>
</ul>
<div class="arithmatex">\[
    U\left(-\sqrt{\frac{6}{n_\mathrm{in} + n_\mathrm{out}}}, \sqrt{\frac{6}{n_\mathrm{in} + n_\mathrm{out}}}\right)
\]</div>
<ul>
<li><code>torch.nn.init.xavier_normal_</code> 函数从正态分布中抽取权重，其中:</li>
</ul>
<div class="arithmatex">\[
    \sigma^2 = \frac{2}{n_\mathrm{in} + n_\mathrm{out}}    
\]</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/czy1101kksk" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://space.bilibili.com/35052889" target="_blank" rel="noopener" title="space.bilibili.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0q13.2 0 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0q13.2 0 21.9 8.603c5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1m-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8s9.7-14.3 10.1-23.5zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5s-17.5-3.2-23.6-9.5-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2s13.2-9.6 23.3-10c9.2.4 17 3.7 23.3 10m191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2s-14 9.5-23.6 9.5-17.4-3.2-23.6-9.5c-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2s14.1-9.6 23.3-10c9.2.4 17 3.7 23.3 10"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:<532651226@qq.com>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../javascripts/extra.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
    
  </body>
</html>