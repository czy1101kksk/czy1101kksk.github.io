
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="BRIGHT_CZY">
      
      
        <link rel="canonical" href="https://czy1101kksk.github.io/sci-paper/cs/Bert/">
      
      
        <link rel="prev" href="../Attention-is-all-you-need/">
      
      
        <link rel="next" href="../MAE/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding - BRIGHT_CZY's site</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="BRIGHT_CZY&#39;s site" class="md-header__button md-logo" aria-label="BRIGHT_CZY's site" data-md-component="logo">
      
  <img src="https://avatars.githubusercontent.com/u/122161543?s=400&u=203bce014a72777aa55f7a4d63a2c98df3bac6e2&v=4" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BRIGHT_CZY's site
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 1 3 3 3 3 0 0 1-3 3 3 3 0 0 1-3-3 3 3 0 0 1 3-3m0-4.5c5 0 9.27 3.11 11 7.5-1.73 4.39-6 7.5-11 7.5S2.73 16.39 1 12c1.73-4.39 6-7.5 11-7.5M3.18 12a9.821 9.821 0 0 0 17.64 0 9.821 9.821 0 0 0-17.64 0"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/czy1101kksk/czy1101kksk.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    BRIGHT_CZY/notebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="BRIGHT_CZY&#39;s site" class="md-nav__button md-logo" aria-label="BRIGHT_CZY's site" data-md-component="logo">
      
  <img src="https://avatars.githubusercontent.com/u/122161543?s=400&u=203bce014a72777aa55f7a4d63a2c98df3bac6e2&v=4" alt="logo">

    </a>
    BRIGHT_CZY's site
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/czy1101kksk/czy1101kksk.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    BRIGHT_CZY/notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    🎆 主页
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            🎆 主页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🎆 主页
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📜 论文阅读
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            📜 论文阅读
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🍥 论文阅读主页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    DL论文
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            DL论文
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../EfficientNet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    EfficientNet
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Attention-is-all-you-need/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention is all you need
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#概述" class="md-nav__link">
    <span class="md-ellipsis">
      概述
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-training" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#总结" class="md-nav__link">
    <span class="md-ellipsis">
      总结
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../MAE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MAE：Masked Autoencoders Are Scalable Vision Learners
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ViT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ViT：An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Distilling-the-knowledge/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distilling the Knowledge in a Neural Network
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Noisy-students/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Self-training with Noisy Student improves ImageNet classification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../MoE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GAN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GAN：Generative Adversarial Nets
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ComputationalPhysics/Transovler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transolver: A Fast Transformer Solver for PDEs on General Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ComputationalPhysics/AeroGTO/aerogto/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AeroGTO:An Efficient Graph-Transformer Operator for Learning Large-Scale Aerodynamics of 3D Vehicle Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ComputationalPhysics/DeepONet/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DeepONet: Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ComputationalPhysics/FNO/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FNO: Fourier Neural Operator for Parametric Partial Differential Equations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ComputationalPhysics/Transovler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transolver: A Fast Transformer Solver for PDEs on General Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ComputationalPhysics/Transolver%2B%2B/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transolver++: An Accurate Neural Solver for PDEs on Million-Scale Geometries
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📰综合能源系统
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            📰综合能源系统
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Load-Forecasting/%5BApplied%20Energy%5DA%20novel%20short-term%20multi-energy%20load%20forecasting%20method%20for%20integrated%20energy%20system%20based%20on%20feature%20separation-fusion%20technology%20and%20improved%20CNN/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    [Applied Energy]A novel short-term multi-energy load forecasting method for integrated energy system based on feature separation-fusion technology and improved CNN
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    👨‍🎓 学习笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            👨‍🎓 学习笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../study-cs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🛠 课程学习主页
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📑专业课程笔记
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            📑专业课程笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../energy/Engineering_Thermodynamics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    工程热力学(甲)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/Python-is-important/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔗Python校内课程笔记
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../energy/heat_transfer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    传热学
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/cs224n-notebook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🛣[Deep Learning]Stanford CS224n:Natural Language Processing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/cs231n/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔭Stanford CS231n:Deep Learning for Computer Vision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/cs224w/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔭Stanford CS224w:Machine Learning with Graphs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/d2l/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🔭Dive into Deeplearing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../python/python-something/fluent-python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    🛣 《流畅的Python》
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    📊 杂项
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            📊 杂项
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/FFT/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    快速傅里叶变换（FFT）
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/RBF/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    径向基函数(Radial basis function)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/GumbelSoftmax/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gumbel-Softmax
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/TensorCalculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    张量分析：Tensor Analysis
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../math/HigherAlgebra/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    高等代数：Higher Algebra 个人笔记
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    ✍ 施工中
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            ✍ 施工中
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../wait-for-me/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    施工中.....
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#概述" class="md-nav__link">
    <span class="md-ellipsis">
      概述
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#embedding" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-training" class="md-nav__link">
    <span class="md-ellipsis">
      Pre-training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fine-tuning" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#总结" class="md-nav__link">
    <span class="md-ellipsis">
      总结
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding<a class="headerlink" href="#bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding" title="Permanent link"></a></h1>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

<div class="admonition info">
<p class="admonition-title">相关信息</p>
<p><font size = 3.5></p>
<p>论文地址：<a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
<p>代码（Pytorch版）:<a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch/tree/master?tab=readme-ov-file">https://github.com/jadore801120/attention-is-all-you-need-pytorch/tree/master?tab=readme-ov-file</a></p>
<p>资源：</p>
<p></font></p>
</div>
<h3 id="概述">概述<a class="headerlink" href="#概述" title="Permanent link"></a></h3>
<p>BERT（Bidirectional Encoder Representations from Transformers）是一种Transformer的双向编码器，旨在通过在左右上下文中共有的条件计算来预先训练来自无标号文本的深度双向表示。因此，经过预先训练的BERT模型只需一个额外的输出层就可以进行微调，从而为各种自然语言处理任务生成最新模型。</p>
<blockquote>
<p>也是我们常说的 【预训练】+【微调】</p>
</blockquote>
<p><img alt="" src="../img/bert1.png" /></p>
<p>BERT的核心思想如下：</p>
<ul>
<li>
<p>随机遮挡句子中一个或多个单词，让Encoder根据句子上下文预测被遮挡的单词（Predict Masked Word）</p>
</li>
<li>
<p>将两个句子拼接，让Encoder判断两个句子是否为原文中相邻的句子(Predict Next Sentence)</p>
</li>
</ul>
<p>BERT通过上述两个任务，预训练Transformer模型Encoder网络。</p>
<p>作者给出了两种不同大小的<code>bert</code>模型：</p>
<ul>
<li>
<p><code>BERT-Base</code>：12 Layers <code>Transformer Encoder</code>，768 Hidden(隐藏单元)，12 Head，110M Parameters.</p>
</li>
<li>
<p><code>BERT-Large</code>：24 Layers <code>Transformer Encoder</code>，1024Hidden(隐藏单元)，16 Head，340M Parameters.</p>
</li>
</ul>
<p><B>Bert直接引用了Transformer架构中的Encoder模块，舍弃了Decoder模块, 由多个Encoder block模块堆叠而成，这样便自动拥有了双向编码能力和强大的特征提取能力。</B></p>
<h3 id="embedding"><code>Embedding</code><a class="headerlink" href="#embedding" title="Permanent link"></a></h3>
<p><img alt="" src="../img/bert2.png" /></p>
<p><code>BERT</code>的输入<code>Embedding</code>模块由三部分组成：</p>
<ul>
<li>
<p><code>Token Embeddings</code>：输入文本中的每个单词或字符转换为一个固定维度的向量。<code>Base</code>版为768维，<code>Large</code>版为1024维。</p>
</li>
<li>
<p><code>Position Embeddings</code>：单词或字符在句子中的位置信息。<code>BERT</code>中的位置嵌入是可学习的，它会随着模型的训练而更新，非固定的三角函数。</p>
</li>
<li>
<p><code>Segment Embeddings</code>：用于区分同一输入序列中不同句子的来源。对于多句输入，<code>BERT</code>会为每个句子分配一个不同的段编号，来区分它们。<code>Segment Embeddings</code>的取值通常是0和1，如果输入包含两个句子，通常第一个句子的<code>token</code>会被赋予全0的向量，第二个句子的token会被赋予全1的向量。下图是一个示例。</p>
</li>
</ul>
<p><img alt="" src="../img/bert3.png" /></p>
<h3 id="pre-training">Pre-training<a class="headerlink" href="#pre-training" title="Permanent link"></a></h3>
<p><code>BERT</code>的预训练过程主要包括两个阶段：<code>Masked Language Model（MLM）</code>和<code>Next Sentence Prediction（NSP）</code>。</p>
<ul>
<li><code>Masked Language Model（MLM）</code>目标：填空，教导<code>BERT</code>上下文</li>
</ul>
<p>为了训练深度双向表示（deep bidirectional representation），在训练过程中，会对每个序类中的15%<code>token</code>随机进行掩码（替换为<code>[MASK]</code>），并且让模型只预测掩码词，而BERT学会从上下文中预测这些单词。这有助于BERT理解单词彼此之间的关系，无论是在前面还是在后面。</p>
<p>事实上，<code>[MASK] token</code>在fine-tuning期间不会出现，因此对于每个被选中的<code>token</code>，有80%的概率直接用<code>[MASK]</code>标记替换，10%的概率用随机的一个单词替换（这有助于模型学习理解上下文的重要性，而不仅仅是依赖于<code>[MASK]</code>标记），剩下的10%则保持不变（这有助于模型在微调阶段更好地处理未遮蔽的单词）。</p>
<p>如图，假设输入句子为<code>[the cat sat on the mat]</code>，被随机遮挡的单词为<code>[cat]</code>，那么<code>BERT</code>的输出为:</p>
<ul>
<li>
<p>80%的时候是<code>[MASK]</code>：<code>[the [[MASK]] sat on the mat]</code></p>
</li>
<li>
<p>10%的时候是随机单词：<code>[the [bike] sat on the mat]</code></p>
</li>
<li>
<p>10%的时候是原词：<code>[the [cat] sat on the mat]</code></p>
</li>
</ul>
<p><img alt="" src="../img/bert4.png" /></p>
<p>这样做使得编码器不知道此次需要预测哪些<code>token</code>或已被随机<code>token</code>替换，因此模型被迫保留每个<code>token</code>的分布上下文表示。（is forced to keep a distributional contextual representation of every input token）</p>
<ul>
<li><code>Next Sentence Prediction（NSP）</code>目标：教导<code>BERT</code>理解句子之间的关系</li>
</ul>
<p>从文本数据中生成训练数据集，抽取两个句子，并将两个句子拼接，两个句子中间用<code>[SEP]</code>符号分隔，在拼接形成的句子前添加一个<code>[CLS]</code>符号(<code>[CLS]</code>是用于分类的标记；<code>[SEP]</code>用于分隔句子。)。其中训练集的50%为文本中相邻的两个句子，另外50%为随机抽取的不相邻两个句子。训练集中相邻句子的标签设置为1，不相邻句子的标签设置为0。</p>
<blockquote>
<p>在<code>BERT</code>的后续版本中，<code>Next Sentence Prediction（NSP）</code>任务被废弃了。因为研究人员发现这个任务对下游任务的性能提升有限，因此在<code>BERT</code>的一些后续变体中被弃用了。</p>
</blockquote>
<p><img alt="" src="../img/bert5.png" /></p>
<p><code>Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]</code></p>
<p><code>Label = IsNext</code></p>
<p><code>Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]</code></p>
<p><code>Label = NotNext</code></p>
<p><img alt="" src="../img/bert6.png" /></p>
<blockquote>
<p>在训练<code>BERT</code>时，为了不使模型认为<code>[MASK]</code>符号原本就归属于训练句子，在随机遮挡单词时采用了将一定数量的<code>[MASK]</code>替换成句子中原本的单词，将一定数量的<code>[MASK]</code>符号替换成随机单词等等小技巧。</p>
</blockquote>
<h3 id="fine-tuning">Fine-tuning<a class="headerlink" href="#fine-tuning" title="Permanent link"></a></h3>
<p><code>self-attention</code> 机制允许 <code>BERT</code> 对任何下游任务建模 —— 无论是 single text 还是 text pairs —— 只需要适当替换输入和输出，因此对 <code>BERT</code> 进行微调是非常方便的。</p>
<p>根据自然语言处理（NLP）下游任务输入和输出形式的不同，微调任务可以分为四类，分别是句对分类、单句分类、文本问答和单句标注</p>
<p><img alt="" src="../img/bert7.png" /></p>
<ul>
<li><code>The General Language Understanding Evaluation (GLUE) benchmark</code></li>
</ul>
<p>GLUE是各种自然语言理解任务的集合，为了对 GLUE 进行微调，我们使用对应于第一个输入标记<code>[CLS]</code>的输出向量<span class="arithmatex">\(C \in \mathbb{R}^H\)</span>，引入一个新的分类层进行分类操作。</p>
<p><img alt="" src="../img/bert8.png" /></p>
<ul>
<li><code>The Stanford Question Answering Dataset (SQuAD v1.1)</code></li>
</ul>
<p>SQuAD v1.1 是100k个公开来源的question/answer对的集合，通常给定一个问题和一个维基百科段落（包含答案），任务是预测文章中的答案文本跨度。</p>
<p><img alt="" src="../img/bert9.png" /></p>
<p>我们将问题和段落表示为单个打包序列输入（输入格式为<code>[CLS]+问题+[SEP]+段落信息</code>），在fine-tuning，我们引入一个起始向量<span class="arithmatex">\(S \in \mathbb{R}^H\)</span>和一个结束向量<span class="arithmatex">\(E \in \mathbb{R}^H\)</span>，来计算答案的开始和结束。</p>
<p>开始位置的计算公式：</p>
<div class="arithmatex">\[
P_i = \frac{e^{S \cdot T_i}}{\sum_{j=1}^{L} e^{S \cdot T_j}}
\]</div>
<p>结束位置的计算公式：</p>
<div class="arithmatex">\[
P_i = \frac{e^{E \cdot T_i}}{\sum_{j=1}^{L} e^{E \cdot T_j}}
\]</div>
<p>从位置 i 到位置 j (i &lt;= j&gt;)的候选跨度的分数定义为:</p>
<div class="arithmatex">\[
Score = S \cdot T_i + E \cdot T_j
\]</div>
<p>最大分值的范围用作预测</p>
<ul>
<li><code>SQuAD 2.0 task</code></li>
</ul>
<p>SQuAD 2.0 任务通过允许提供的段落中不存在答案的可能性来扩展 SQuAD 1.1 问题定义，从而使问题更加现实。</p>
<p>若不存在答案，则计算一个没有答案的得分：</p>
<div class="arithmatex">\[
Score = S \cdot C + E \cdot C
\]</div>
<p>其中<span class="arithmatex">\(C\)</span>就是<code>[CLS]</code>的对应输出，此时如果没有答案的分数要比找到的答案的分数要好，那么就预测为没有答案。</p>
<ul>
<li><code>The Situations With Adversarial Generations (SWAG) dataset</code> </li>
</ul>
<details> 
<summary>BERT简洁实现</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1">  1</a></span>
<span class="normal"><a href="#__codelineno-0-2">  2</a></span>
<span class="normal"><a href="#__codelineno-0-3">  3</a></span>
<span class="normal"><a href="#__codelineno-0-4">  4</a></span>
<span class="normal"><a href="#__codelineno-0-5">  5</a></span>
<span class="normal"><a href="#__codelineno-0-6">  6</a></span>
<span class="normal"><a href="#__codelineno-0-7">  7</a></span>
<span class="normal"><a href="#__codelineno-0-8">  8</a></span>
<span class="normal"><a href="#__codelineno-0-9">  9</a></span>
<span class="normal"><a href="#__codelineno-0-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-0-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-0-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-0-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-0-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-0-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-0-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-0-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-0-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-0-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-0-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-0-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-0-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-0-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-0-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-0-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-0-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-0-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-0-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-0-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-0-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-0-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-0-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-0-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-0-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-0-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-0-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-0-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-0-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-0-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-0-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-0-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-0-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-0-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-0-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-0-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-0-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-0-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-0-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-0-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-0-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-0-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-0-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-0-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-0-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-0-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-0-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-0-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-0-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-0-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-0-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-0-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-0-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-0-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-0-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-0-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-0-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-0-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-0-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-0-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-0-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-0-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-0-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-0-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-0-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-0-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-0-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-0-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-0-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-0-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-0-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-0-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-0-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-0-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-0-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-0-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-0-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-0-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-0-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-0-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-0-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-0-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-0-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-0-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-0-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-0-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-0-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-0-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-0-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-0-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-0-100">100</a></span>
<span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span>
<span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span>
<span class="normal"><a href="#__codelineno-0-211">211</a></span>
<span class="normal"><a href="#__codelineno-0-212">212</a></span>
<span class="normal"><a href="#__codelineno-0-213">213</a></span>
<span class="normal"><a href="#__codelineno-0-214">214</a></span>
<span class="normal"><a href="#__codelineno-0-215">215</a></span>
<span class="normal"><a href="#__codelineno-0-216">216</a></span>
<span class="normal"><a href="#__codelineno-0-217">217</a></span>
<span class="normal"><a href="#__codelineno-0-218">218</a></span>
<span class="normal"><a href="#__codelineno-0-219">219</a></span>
<span class="normal"><a href="#__codelineno-0-220">220</a></span>
<span class="normal"><a href="#__codelineno-0-221">221</a></span>
<span class="normal"><a href="#__codelineno-0-222">222</a></span>
<span class="normal"><a href="#__codelineno-0-223">223</a></span>
<span class="normal"><a href="#__codelineno-0-224">224</a></span>
<span class="normal"><a href="#__codelineno-0-225">225</a></span>
<span class="normal"><a href="#__codelineno-0-226">226</a></span>
<span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span>
<span class="normal"><a href="#__codelineno-0-234">234</a></span>
<span class="normal"><a href="#__codelineno-0-235">235</a></span>
<span class="normal"><a href="#__codelineno-0-236">236</a></span>
<span class="normal"><a href="#__codelineno-0-237">237</a></span>
<span class="normal"><a href="#__codelineno-0-238">238</a></span>
<span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="c1"># sample IsNext and NotNext to be same in small batch size</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span><span class="w"> </span><span class="nf">make_batch</span><span class="p">():</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="sd">    word_dict</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    number_dict</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    positive = negative-&gt;int : 正样本/负样本数量</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    input_ids-&gt;list: 模型输入的token id</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    segment_ids: 区分句子的segment id</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    n_pred: 通过MASK后模型要预测的token数量</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    n_pad: padding数量，使batch中的句子长度一致</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    max_pred: 预测的最大掩码数量</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    masked_tokens: MASK的token</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    masked_pos: MASK的token的位置</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    &#39;&#39;&#39;</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="n">positive</span> <span class="o">=</span> <span class="n">negative</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># 正样本IsNext和负样本NotNext的数量</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">while</span> <span class="n">positive</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="o">/</span><span class="mi">2</span> <span class="ow">or</span> <span class="n">negative</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="n">tokens_a_index</span><span class="p">,</span> <span class="n">tokens_b_index</span> <span class="o">=</span> <span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)),</span> <span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">))</span> <span class="c1"># sample random index in sentences</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="n">tokens_a</span><span class="p">,</span> <span class="n">tokens_b</span><span class="o">=</span> <span class="n">token_list</span><span class="p">[</span><span class="n">tokens_a_index</span><span class="p">],</span> <span class="n">token_list</span><span class="p">[</span><span class="n">tokens_b_index</span><span class="p">]</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="n">input_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_dict</span><span class="p">[</span><span class="s1">&#39;[CLS]&#39;</span><span class="p">]]</span> <span class="o">+</span> <span class="n">tokens_a</span> <span class="o">+</span> <span class="p">[</span><span class="n">word_dict</span><span class="p">[</span><span class="s1">&#39;[SEP]&#39;</span><span class="p">]]</span> <span class="o">+</span> <span class="n">tokens_b</span> <span class="o">+</span> <span class="p">[</span><span class="n">word_dict</span><span class="p">[</span><span class="s1">&#39;[SEP]&#39;</span><span class="p">]]</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="n">segment_ids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens_a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens_b</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="c1"># MASK LM</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="n">n_pred</span> <span class="o">=</span>  <span class="nb">min</span><span class="p">(</span><span class="n">max_pred</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.15</span><span class="p">))))</span> <span class="c1"># 15 % of tokens in one sentence</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="n">cand_maked_pos</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>                          <span class="k">if</span> <span class="n">token</span> <span class="o">!=</span> <span class="n">word_dict</span><span class="p">[</span><span class="s1">&#39;[CLS]&#39;</span><span class="p">]</span> <span class="ow">and</span> <span class="n">token</span> <span class="o">!=</span> <span class="n">word_dict</span><span class="p">[</span><span class="s1">&#39;[SEP]&#39;</span><span class="p">]]</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="n">shuffle</span><span class="p">(</span><span class="n">cand_maked_pos</span><span class="p">)</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>        <span class="n">masked_tokens</span><span class="p">,</span> <span class="n">masked_pos</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">cand_maked_pos</span><span class="p">[:</span><span class="n">n_pred</span><span class="p">]:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>            <span class="n">masked_pos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>            <span class="n">masked_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">pos</span><span class="p">])</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>            <span class="k">if</span> <span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">:</span>  <span class="c1"># 80%</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>                <span class="n">input_ids</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">word_dict</span><span class="p">[</span><span class="s1">&#39;[MASK]&#39;</span><span class="p">]</span> <span class="c1"># make mask</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>            <span class="k">elif</span> <span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>  <span class="c1"># 10%</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>                <span class="n">index</span> <span class="o">=</span> <span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># random index in vocabulary</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>                <span class="n">input_ids</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">word_dict</span><span class="p">[</span><span class="n">number_dict</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span> <span class="c1"># replace</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>        <span class="c1"># Zero Paddings</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="n">n_pad</span> <span class="o">=</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">input_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_pad</span><span class="p">)</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>        <span class="n">segment_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_pad</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="c1"># Zero Padding (100% - 15%) tokens</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="k">if</span> <span class="n">max_pred</span> <span class="o">&gt;</span> <span class="n">n_pred</span><span class="p">:</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>            <span class="n">n_pad</span> <span class="o">=</span> <span class="n">max_pred</span> <span class="o">-</span> <span class="n">n_pred</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="n">masked_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_pad</span><span class="p">)</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>            <span class="n">masked_pos</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_pad</span><span class="p">)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="k">if</span> <span class="n">tokens_a_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">tokens_b_index</span> <span class="ow">and</span> <span class="n">positive</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>            <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_tokens</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">,</span> <span class="kc">True</span><span class="p">])</span> <span class="c1"># IsNext</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>            <span class="n">positive</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="k">elif</span> <span class="n">tokens_a_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">!=</span> <span class="n">tokens_b_index</span> <span class="ow">and</span> <span class="n">negative</span> <span class="o">&lt;</span> <span class="n">batch_size</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>            <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_tokens</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span> <span class="c1"># NotNext</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>            <span class="n">negative</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="k">return</span> <span class="n">batch</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="c1"># Proprecessing Finished</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_attn_pad_mask</span><span class="p">(</span><span class="n">seq_q</span><span class="p">,</span> <span class="n">seq_k</span><span class="p">):</span> <span class="c1"># 对&lt;PAD&gt;的掩码</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>    <span class="n">batch_size</span><span class="p">,</span> <span class="n">len_q</span> <span class="o">=</span> <span class="n">seq_q</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>    <span class="n">batch_size</span><span class="p">,</span> <span class="n">len_k</span> <span class="o">=</span> <span class="n">seq_k</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>    <span class="c1"># eq(zero) is PAD token</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>    <span class="n">pad_attn_mask</span> <span class="o">=</span> <span class="n">seq_k</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># batch_size x 1 x len_k(=len_q), one is masking</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="k">return</span> <span class="n">pad_attn_mask</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">len_q</span><span class="p">,</span> <span class="n">len_k</span><span class="p">)</span>  <span class="c1"># batch_size x len_q x len_k</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="k">def</span><span class="w"> </span><span class="nf">gelu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="s2">&quot;Implementation of the gelu activation function by Hugging Face&quot;</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)))</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="k">class</span><span class="w"> </span><span class="nc">Embedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">Embedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">tok_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>  <span class="c1"># token embedding</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">maxlen</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>  <span class="c1"># position embedding</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">seg_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_segments</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>  <span class="c1"># segment(token type) embedding</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">seg</span><span class="p">):</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">seq_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (seq_len,) -&gt; (batch_size, seq_len)</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="n">embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tok_embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">seg_embed</span><span class="p">(</span><span class="n">seg</span><span class="p">)</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="k">class</span><span class="w"> </span><span class="nc">ScaledDotProductAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">ScaledDotProductAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">):</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d_k</span><span class="p">)</span> <span class="c1"># scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="n">scores</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">attn_mask</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span> <span class="c1"># Fills elements of self tensor with value where mask is one.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>        <span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span><span class="n">scores</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attn</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="k">return</span> <span class="n">context</span><span class="p">,</span> <span class="n">attn</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="k">class</span><span class="w"> </span><span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_k</span> <span class="o">*</span> <span class="n">n_heads</span><span class="p">)</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_k</span> <span class="o">*</span> <span class="n">n_heads</span><span class="p">)</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_v</span> <span class="o">*</span> <span class="n">n_heads</span><span class="p">)</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">):</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="c1"># q: [batch_size x len_q x d_model] </span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>        <span class="c1"># k: [batch_size x len_k x d_model] </span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="c1"># v: [batch_size x len_k x d_model]</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">residual</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">Q</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="c1"># (B, S, D) -proj-&gt; (B, S, D) -split-&gt; (B, S, H, W) -trans-&gt; (B, H, S, W)</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>        <span class="n">q_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_Q</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">d_k</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># q_s: [batch_size x n_heads x len_q x d_k]</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="n">k_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_K</span><span class="p">(</span><span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">d_k</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># k_s: [batch_size x n_heads x len_k x d_k]</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>        <span class="n">v_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_V</span><span class="p">(</span><span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">d_v</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># v_s: [batch_size x n_heads x len_k x d_v]</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>        <span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># attn_mask : [batch_size x n_heads x len_q x len_k]</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="c1"># context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="n">context</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">ScaledDotProductAttention</span><span class="p">()(</span><span class="n">q_s</span><span class="p">,</span> <span class="n">k_s</span><span class="p">,</span> <span class="n">v_s</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">d_v</span><span class="p">)</span> <span class="c1"># context: [batch_size x len_q x n_heads * d_v]</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_heads</span> <span class="o">*</span> <span class="n">d_v</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)(</span><span class="n">context</span><span class="p">)</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)(</span><span class="n">output</span> <span class="o">+</span> <span class="n">residual</span><span class="p">),</span> <span class="n">attn</span> <span class="c1"># output: [batch_size x len_q x d_model]</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="k">class</span><span class="w"> </span><span class="nc">PoswiseFeedForwardNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">PoswiseFeedForwardNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ff</span><span class="p">)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ff</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="c1"># (batch_size, len_seq, d_model) -&gt; (batch_size, len_seq, d_ff) -&gt; (batch_size, len_seq, d_model)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">gelu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="k">class</span><span class="w"> </span><span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">enc_self_attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">()</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">pos_ffn</span> <span class="o">=</span> <span class="n">PoswiseFeedForwardNet</span><span class="p">()</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_inputs</span><span class="p">,</span> <span class="n">enc_self_attn_mask</span><span class="p">):</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_self_attn</span><span class="p">(</span><span class="n">enc_inputs</span><span class="p">,</span> <span class="n">enc_inputs</span><span class="p">,</span> <span class="n">enc_inputs</span><span class="p">,</span> <span class="n">enc_self_attn_mask</span><span class="p">)</span> <span class="c1"># enc_inputs to same Q,K,V</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_ffn</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">)</span> <span class="c1"># enc_outputs: [batch_size x len_q x d_model]</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="k">return</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">attn</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="k">class</span><span class="w"> </span><span class="nc">BERT</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">BERT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">()</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">EncoderLayer</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activ1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">activ2</span> <span class="o">=</span> <span class="n">gelu</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="c1"># decoder is shared with embedding layer</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="n">embed_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">tok_embed</span><span class="o">.</span><span class="n">weight</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="n">n_vocab</span><span class="p">,</span> <span class="n">n_dim</span> <span class="o">=</span> <span class="n">embed_weight</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_dim</span><span class="p">,</span> <span class="n">n_vocab</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">embed_weight</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_vocab</span><span class="p">))</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">):</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>        <span class="n">enc_self_attn_mask</span> <span class="o">=</span> <span class="n">get_attn_pad_mask</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">)</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>            <span class="n">output</span><span class="p">,</span> <span class="n">enc_self_attn</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">enc_self_attn_mask</span><span class="p">)</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>        <span class="c1"># output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>        <span class="c1"># it will be decided by first token(CLS)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>        <span class="n">h_pooled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activ1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span> <span class="c1"># [batch_size, d_model]</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>        <span class="n">logits_clsf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">h_pooled</span><span class="p">)</span> <span class="c1"># [batch_size, 2]</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="n">masked_pos</span> <span class="o">=</span> <span class="n">masked_pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># [batch_size, max_pred, d_model]</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>        <span class="c1"># 用None来增加一个维度，将 masked_pos 从[batch_size, max_pred] —&gt; [batch_size, max_pred, 1]</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="c1"># get masked position from final output of transformer.</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>        <span class="n">h_masked</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">)</span> 
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>        <span class="c1"># torch.gather(input, dim=0, index) 取值</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>        <span class="c1"># masking position [batch_size, max_pred, d_model]</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">h_masked</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activ2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">h_masked</span><span class="p">)))</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>        <span class="n">logits_lm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">h_masked</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_bias</span> <span class="c1"># [batch_size, max_pred, n_vocab]</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="k">return</span> <span class="n">logits_lm</span><span class="p">,</span> <span class="n">logits_clsf</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="c1"># BERT Parameters</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="n">maxlen</span> <span class="o">=</span> <span class="mi">30</span> <span class="c1"># maximum of length</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">6</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="n">max_pred</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># max tokens of prediction</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="n">n_layers</span> <span class="o">=</span> <span class="mi">6</span> <span class="c1"># number of Encoder of Encoder Layer</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="n">n_heads</span> <span class="o">=</span> <span class="mi">12</span> <span class="c1"># number of heads in Multi-Head Attention</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">768</span> <span class="c1"># Embedding Size</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="n">d_ff</span> <span class="o">=</span> <span class="mi">768</span> <span class="o">*</span> <span class="mi">4</span>  <span class="c1"># 4*d_model, FeedForward dimension</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">d_k</span> <span class="o">=</span> <span class="n">d_v</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># dimension of K(=Q), V</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="n">n_segments</span> <span class="o">=</span> <span class="mi">2</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="n">text</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="s1">&#39;Hello, how are you? I am Romeo.</span><span class="se">\n</span><span class="s1">&#39;</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="s1">&#39;Hello, Romeo My name is Juliet. Nice to meet you.</span><span class="se">\n</span><span class="s1">&#39;</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>        <span class="s1">&#39;Nice meet you too. How are you today?</span><span class="se">\n</span><span class="s1">&#39;</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="s1">&#39;Great. My baseball team won the competition.</span><span class="se">\n</span><span class="s1">&#39;</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="s1">&#39;Oh Congratulations, Juliet</span><span class="se">\n</span><span class="s1">&#39;</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="s1">&#39;Thanks you Romeo&#39;</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="p">)</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="n">sentences</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;[.,!?</span><span class="se">\\</span><span class="s2">-]&quot;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>  <span class="c1"># filter &#39;.&#39;, &#39;,&#39;, &#39;?&#39;, &#39;!&#39;</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>    <span class="n">word_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="n">word_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;[PAD]&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;[CLS]&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;[SEP]&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;[MASK]&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_list</span><span class="p">):</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>        <span class="n">word_dict</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">4</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="n">number_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_dict</span><span class="p">)}</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>    <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_dict</span><span class="p">)</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>    <span class="n">token_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="n">arr</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_dict</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>        <span class="n">token_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>    <span class="n">model</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">()</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>    <span class="n">batch</span> <span class="o">=</span> <span class="n">make_batch</span><span class="p">()</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>    <span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_tokens</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">,</span> <span class="n">isNext</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">))</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>        <span class="n">logits_lm</span><span class="p">,</span> <span class="n">logits_clsf</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">)</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>        <span class="n">loss_lm</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits_lm</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">masked_tokens</span><span class="p">)</span> <span class="c1"># for masked LM</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>        <span class="n">loss_lm</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_lm</span><span class="o">.</span><span class="n">float</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="n">loss_clsf</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits_clsf</span><span class="p">,</span> <span class="n">isNext</span><span class="p">)</span> <span class="c1"># for sentence classification</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_lm</span> <span class="o">+</span> <span class="n">loss_clsf</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch:&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%04d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;cost =&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>    <span class="c1"># Predict mask tokens ans isNext</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>    <span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_tokens</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">,</span> <span class="n">isNext</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>    <span class="nb">print</span><span class="p">([</span><span class="n">number_dict</span><span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">number_dict</span><span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="o">!=</span> <span class="s1">&#39;[PAD]&#39;</span><span class="p">])</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>    <span class="n">logits_lm</span><span class="p">,</span> <span class="n">logits_clsf</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">masked_pos</span><span class="p">)</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>    <span class="n">logits_lm</span> <span class="o">=</span> <span class="n">logits_lm</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;masked tokens list : &#39;</span><span class="p">,[</span><span class="n">pos</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">masked_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">pos</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predict masked tokens list : &#39;</span><span class="p">,[</span><span class="n">pos</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">logits_lm</span> <span class="k">if</span> <span class="n">pos</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>    <span class="n">logits_clsf</span> <span class="o">=</span> <span class="n">logits_clsf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;isNext : &#39;</span><span class="p">,</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">isNext</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;predict isNext : &#39;</span><span class="p">,</span><span class="kc">True</span> <span class="k">if</span> <span class="n">logits_clsf</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>

</details>

<h3 id="总结">总结<a class="headerlink" href="#总结" title="Permanent link"></a></h3>
<ul>
<li>
<p>深度双向预训练表示：</p>
<p>与以往的语言表示模型不同，BERT旨在通过联合考虑所有层中的左侧和右侧上下文来预训练深度双向表示。这使得BERT能够在预训练阶段捕获更丰富的语言特征。</p>
</li>
<li>
<p>简化的任务特定架构修改：</p>
<p>预训练的BERT模型可以通过添加少量额外的输出层来微调（fine-tune），从而适应广泛的任务，如问答和语言推断，而无需对模型架构进行大量特定任务的修改。</p>
</li>
<li>
<p>多项自然语言处理任务的新最佳结果：</p>
<p>BERT在十一个自然语言处理任务上取得了新的最先进结果，包括将GLUE基准的分数推高到80.5%（绝对提高了7.7个百分点），MultiNLI准确率提高到86.7%（提高了4.6个百分点），SQuAD v1.1问答测试的F1分数提高到93.2（提高了1.5个百分点），以及SQuAD v2.0测试的F1分数提高到83.1（提高了5.1个百分点）。</p>
</li>
<li>
<p>预训练任务的重要性(<B>预训练词嵌入，</p>
<p>性能优于从头开始学习的嵌入</B>)：BERT通过使用“掩码语言模型”（Masked Language Model, MLM）和“下一句预测”%（Next Sentence Prediction, NSP）任务来展示深度双向预训练的重要性。MLM任务通过随机掩盖输入中的一些标记，然后预测这些掩盖标记的原始词汇ID，从而使得模型能够融合左右上下文。NSP任务则通过预测两个文本片段之间的关系来训练模型理解句子间的关系。</p>
</li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/czy1101kksk" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://space.bilibili.com/35052889" target="_blank" rel="noopener" title="space.bilibili.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0q13.2 0 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0q13.2 0 21.9 8.603c5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1m-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8s9.7-14.3 10.1-23.5zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5s-17.5-3.2-23.6-9.5-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2s13.2-9.6 23.3-10c9.2.4 17 3.7 23.3 10m191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2s-14 9.5-23.6 9.5-17.4-3.2-23.6-9.5c-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2s14.1-9.6 23.3-10c9.2.4 17 3.7 23.3 10"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:<532651226@qq.com>" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../../../javascripts/extra.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
    
  </body>
</html>